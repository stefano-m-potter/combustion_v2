{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46d5db2d-5463-4a16-9369-1e367eef1a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üöÄ STARTING PDP (New Data only)\n",
      "======================================================================\n",
      "New Data rows: 867\n",
      "\n",
      "‚Äî Target: above.carbon.combusted\n",
      "  ‚úì Trained RF (n=867)\n",
      "\n",
      "‚Äî Target: below.ground.carbon.combusted\n",
      "  ‚úì Trained RF (n=867)\n",
      "\n",
      "‚Äî Target: burn.depth\n",
      "  ‚úì Trained RF (n=866)\n",
      "\n",
      "======================================================================\n",
      "üéâ Done. Large-font PDPs saved in *_new_3x2 folders.\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "# -------------------- Config --------------------\n",
    "INPUT_CSV = \"/explore/nobackup/people/spotter5/new_combustion/2025-08-13_LC_FISL_Original_combustionModelPredictors.csv\"\n",
    "OLD_PREDICTORS_CSV = \"/explore/nobackup/people/spotter5/new_combustion/Combustion_SynthesisData_05042018_XJW.csv\"\n",
    "BASE_OUT_PATH = \"/explore/nobackup/people/spotter5/new_combustion\"\n",
    "\n",
    "OUT_DIRS = {\n",
    "    'above.carbon.combusted': os.path.join(BASE_OUT_PATH, \"pdp_aboveground_fisl\"),\n",
    "    'below.ground.carbon.combusted': os.path.join(BASE_OUT_PATH, \"pdp_belowground_fisl\"),\n",
    "    'burn.depth': os.path.join(BASE_OUT_PATH, \"pdp_depth_fisl\"),\n",
    "}\n",
    "\n",
    "POTENTIAL_TARGETS = ['below.ground.carbon.combusted', 'above.carbon.combusted', 'burn.depth']\n",
    "METADATA_COLUMNS = ['burn_year','project.name','latitude','longitude','Date','id','CNA_MAR',\n",
    "                    'fireYr','lat','lon','project_name']\n",
    "COLS_TO_DROP_FROM_X = POTENTIAL_TARGETS + METADATA_COLUMNS\n",
    "\n",
    "TOP6 = {\n",
    "    'above.carbon.combusted': ['BS','twi','brightness','ISI','Tree.cover','Temperature'],\n",
    "    'below.ground.carbon.combusted': ['BUI','twi','CNA_PAS','Silt_30','brightness','NV'],\n",
    "    'burn.depth': ['BUI','twi','CNA_PAS','CNA_DD_0','WS','DC'],\n",
    "}\n",
    "\n",
    "# -------------------- Helpers --------------------\n",
    "def normalize_name(s):\n",
    "    return \"\".join(ch for ch in str(s).lower() if ch.isalnum())\n",
    "\n",
    "def map_requested_features_to_columns(requested, df_columns):\n",
    "    norm_map = {normalize_name(c): c for c in df_columns}\n",
    "    mapped, missing = [], []\n",
    "    for r in requested:\n",
    "        nr = normalize_name(r)\n",
    "        if nr in norm_map:\n",
    "            mapped.append(norm_map[nr])\n",
    "        else:\n",
    "            missing.append(r)\n",
    "    return mapped, missing\n",
    "\n",
    "def median_impute_numeric(df):\n",
    "    out = df.copy()\n",
    "    num_cols = out.select_dtypes(include=[np.number]).columns\n",
    "    out[num_cols] = out[num_cols].fillna(out[num_cols].median())\n",
    "    return out\n",
    "\n",
    "# -------------------- Load and split --------------------\n",
    "print(f\"\\n{'='*70}\\nüöÄ STARTING PDP (New Data only)\\n{'='*70}\")\n",
    "df_main = pd.read_csv(INPUT_CSV)\n",
    "df_old  = pd.read_csv(OLD_PREDICTORS_CSV)\n",
    "\n",
    "old_ids = pd.unique(df_old['id'])\n",
    "df_new  = df_main[~df_main['id'].isin(old_ids)].copy()\n",
    "print(f\"New Data rows: {len(df_new)}\")\n",
    "\n",
    "# -------------------- Train & plot --------------------\n",
    "for target in OUT_DIRS:\n",
    "    os.makedirs(OUT_DIRS[target], exist_ok=True)\n",
    "    print(f\"\\n‚Äî Target: {target}\")\n",
    "\n",
    "    if target not in df_new.columns:\n",
    "        print(f\"  ‚ö†Ô∏è Target '{target}' not found. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    df_t = df_new.dropna(subset=[target]).copy()\n",
    "    if df_t.empty:\n",
    "        print(f\"  ‚ö†Ô∏è No rows with non-NA '{target}'. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    X = df_t.drop(columns=COLS_TO_DROP_FROM_X, errors='ignore').select_dtypes(include=[np.number])\n",
    "    if X.shape[1] == 0:\n",
    "        print(\"  ‚ö†Ô∏è No numeric predictors after exclusions. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    X_imp = median_impute_numeric(X)\n",
    "    y = df_t[target].astype(float)\n",
    "\n",
    "    rf = RandomForestRegressor(n_estimators=500, random_state=42, n_jobs=-1, oob_score=len(y)>10)\n",
    "    rf.fit(X_imp, y)\n",
    "    print(f\"  ‚úì Trained RF (n={len(y)})\")\n",
    "\n",
    "    mapped, missing = map_requested_features_to_columns(TOP6[target], X_imp.columns)\n",
    "    if missing:\n",
    "        print(f\"  ‚ö†Ô∏è Missing requested features: {missing}\")\n",
    "    if not mapped:\n",
    "        continue\n",
    "\n",
    "    # 3x2 figure with bigger fonts\n",
    "    fig, axes = plt.subplots(3, 2, figsize=(16, 20))\n",
    "    axes = axes.ravel()\n",
    "    for i in range(6):\n",
    "        ax = axes[i]\n",
    "        if i < len(mapped):\n",
    "            feat = mapped[i]\n",
    "            try:\n",
    "                PartialDependenceDisplay.from_estimator(\n",
    "                    rf, X_imp, [feat], ax=ax, line_kw={\"linewidth\": 3})\n",
    "                ax.set_title(feat, fontsize=18)\n",
    "                ax.set_xlabel(ax.get_xlabel(), fontsize=16)\n",
    "                ax.set_ylabel(ax.get_ylabel(), fontsize=16)\n",
    "                ax.tick_params(axis='both', labelsize=14)\n",
    "                ax.grid(True, linestyle='--', alpha=0.6)\n",
    "            except Exception as e:\n",
    "                ax.text(0.5,0.5,f\"PDP failed\\n{feat}\\n{e}\",ha='center',va='center',\n",
    "                        fontsize=16,color='red')\n",
    "                ax.axis('off')\n",
    "        else:\n",
    "            ax.axis('off')\n",
    "\n",
    "    pretty = {'above.carbon.combusted':'Aboveground Carbon',\n",
    "              'below.ground.carbon.combusted':'Belowground Carbon',\n",
    "              'burn.depth':'Burn Depth'}[target]\n",
    "    fig.suptitle(f'New Data ‚Äî Top 6 PDPs ({pretty})', fontsize=24, y=0.98)\n",
    "\n",
    "    save_path = os.path.join(OUT_DIRS[target], f\"pdp_new_{target.replace('.', '_')}_3x2.png\")\n",
    "    plt.tight_layout(rect=[0,0,1,0.96])\n",
    "    plt.savefig(save_path, dpi=150)\n",
    "    plt.close(fig)\n",
    "\n",
    "print(f\"\\n{'='*70}\\nüéâ Done. Large-font PDPs saved in *_new_3x2 folders.\\n{'='*70}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c43fb329-1e2c-427a-9e46-a7b6b63f8750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üöÄ STARTING PDP (New Data only)\n",
      "======================================================================\n",
      "New Data rows: 867\n",
      "\n",
      "‚Äî Target: above.carbon.combusted\n",
      "  ‚úì Trained RF (n=867)\n",
      "\n",
      "‚Äî Target: below.ground.carbon.combusted\n",
      "  ‚úì Trained RF (n=867)\n",
      "\n",
      "‚Äî Target: burn.depth\n",
      "  ‚úì Trained RF (n=866)\n",
      "\n",
      "======================================================================\n",
      "üéâ Done. Axis labels are now force-sized after PDP draws.\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "# -------------------- Font/Style: force larger text everywhere --------------------\n",
    "FS_SUPTITLE = 36   # figure title\n",
    "FS_LABEL    = 26   # x/y axis labels\n",
    "FS_TICKS    = 22   # tick labels\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"font.size\": FS_TICKS,           # base font size\n",
    "    \"axes.titlesize\": FS_SUPTITLE,   # not used (no subplot titles), but safe\n",
    "    \"axes.labelsize\": FS_LABEL,      # default axis-label size\n",
    "    \"xtick.labelsize\": FS_TICKS,\n",
    "    \"ytick.labelsize\": FS_TICKS,\n",
    "    \"legend.fontsize\": FS_TICKS,\n",
    "})\n",
    "\n",
    "# -------------------- Config --------------------\n",
    "INPUT_CSV = \"/explore/nobackup/people/spotter5/new_combustion/2025-08-13_LC_FISL_Original_combustionModelPredictors.csv\"\n",
    "OLD_PREDICTORS_CSV = \"/explore/nobackup/people/spotter5/new_combustion/Combustion_SynthesisData_05042018_XJW.csv\"\n",
    "BASE_OUT_PATH = \"/explore/nobackup/people/spotter5/new_combustion\"\n",
    "\n",
    "OUT_DIRS = {\n",
    "    'above.carbon.combusted': os.path.join(BASE_OUT_PATH, \"pdp_aboveground_fisl\"),\n",
    "    'below.ground.carbon.combusted': os.path.join(BASE_OUT_PATH, \"pdp_belowground_fisl\"),\n",
    "    'burn.depth': os.path.join(BASE_OUT_PATH, \"pdp_depth_fisl\"),\n",
    "}\n",
    "\n",
    "# Excluded predictor columns\n",
    "POTENTIAL_TARGETS = ['below.ground.carbon.combusted', 'above.carbon.combusted', 'burn.depth']\n",
    "METADATA_COLUMNS = ['burn_year','project.name','latitude','longitude','Date','id','CNA_MAR',\n",
    "                    'fireYr','lat','lon','project_name']\n",
    "COLS_TO_DROP_FROM_X = POTENTIAL_TARGETS + METADATA_COLUMNS\n",
    "\n",
    "# Top-6 features per target\n",
    "TOP6 = {\n",
    "    'above.carbon.combusted': ['BS','twi','brightness','ISI','Tree.cover','Temperature'],\n",
    "    'below.ground.carbon.combusted': ['BUI','twi','CNA_PAS','Silt_30','brightness','NV'],\n",
    "    'burn.depth': ['BUI','twi','CNA_PAS','CNA_DD_0','WS','DC'],\n",
    "}\n",
    "\n",
    "# Plot style\n",
    "HIST_BINS  = 40\n",
    "HIST_ALPHA = 0.30\n",
    "HIST_COLOR = 'skyblue'\n",
    "\n",
    "# -------------------- Helpers --------------------\n",
    "def normalize_name(s):\n",
    "    return \"\".join(ch for ch in str(s).lower() if ch.isalnum())\n",
    "\n",
    "def map_requested_features_to_columns(requested, df_columns):\n",
    "    norm_map = {normalize_name(c): c for c in df_columns}\n",
    "    mapped, missing = [], []\n",
    "    for r in requested:\n",
    "        key = normalize_name(r)\n",
    "        if key in norm_map:\n",
    "            mapped.append(norm_map[key])\n",
    "        else:\n",
    "            missing.append(r)\n",
    "    return mapped, missing\n",
    "\n",
    "def median_impute_numeric(df):\n",
    "    out = df.copy()\n",
    "    num_cols = out.select_dtypes(include=[np.number]).columns\n",
    "    out[num_cols] = out[num_cols].fillna(out[num_cols].median())\n",
    "    return out\n",
    "\n",
    "# -------------------- Load and split --------------------\n",
    "print(f\"\\n{'='*70}\\nüöÄ STARTING PDP (New Data only)\\n{'='*70}\")\n",
    "df_main = pd.read_csv(INPUT_CSV)\n",
    "df_old  = pd.read_csv(OLD_PREDICTORS_CSV)\n",
    "\n",
    "if 'id' not in df_main.columns or 'id' not in df_old.columns:\n",
    "    raise SystemExit(\"‚ùå Both files must have an 'id' column.\")\n",
    "\n",
    "old_ids = pd.unique(df_old['id'])\n",
    "df_new  = df_main[~df_main['id'].isin(old_ids)].copy()\n",
    "print(f\"New Data rows: {len(df_new)}\")\n",
    "\n",
    "# -------------------- Train & plot --------------------\n",
    "for target in OUT_DIRS:\n",
    "    os.makedirs(OUT_DIRS[target], exist_ok=True)\n",
    "    print(f\"\\n‚Äî Target: {target}\")\n",
    "\n",
    "    if target not in df_new.columns:\n",
    "        print(f\"  ‚ö†Ô∏è Target '{target}' not found. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    df_t = df_new.dropna(subset=[target]).copy()\n",
    "    if df_t.empty:\n",
    "        print(f\"  ‚ö†Ô∏è No rows with non-NA '{target}'. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    X = df_t.drop(columns=COLS_TO_DROP_FROM_X, errors='ignore').select_dtypes(include=[np.number])\n",
    "    if X.shape[1] == 0:\n",
    "        print(\"  ‚ö†Ô∏è No numeric predictors after exclusions. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    X_imp = median_impute_numeric(X)\n",
    "    y = df_t[target].astype(float)\n",
    "\n",
    "    rf = RandomForestRegressor(\n",
    "        n_estimators=500,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        oob_score=len(y) > 10\n",
    "    )\n",
    "    rf.fit(X_imp, y)\n",
    "    print(f\"  ‚úì Trained RF (n={len(y)})\")\n",
    "\n",
    "    requested = TOP6[target]\n",
    "    mapped, missing = map_requested_features_to_columns(requested, X_imp.columns)\n",
    "    if not mapped:\n",
    "        print(\"  ‚ö†Ô∏è No requested features found. Skipping PDP.\")\n",
    "        continue\n",
    "\n",
    "    fig, axes = plt.subplots(3, 2, figsize=(22, 26))\n",
    "    axes = axes.ravel()\n",
    "\n",
    "    for i in range(6):\n",
    "        ax = axes[i]\n",
    "        if i < len(mapped):\n",
    "            feat = mapped[i]\n",
    "            try:\n",
    "                # Draw PDP (this sets labels internally)\n",
    "                PartialDependenceDisplay.from_estimator(\n",
    "                    rf, X_imp, [feat], ax=ax,\n",
    "                    line_kw={\"linewidth\": 4, \"color\": \"black\"}\n",
    "                )\n",
    "            except Exception as e:\n",
    "                ax.text(0.5, 0.5, f\"PDP failed\\n{feat}\\n{e}\",\n",
    "                        ha='center', va='center', fontsize=FS_LABEL, color='red')\n",
    "                ax.axis('off')\n",
    "                continue\n",
    "\n",
    "            # ----- FORCE bigger axis label fonts AFTER PDP draws -----\n",
    "            ax.set_xlabel(feat)  # ensure xlabel text\n",
    "            ax.set_ylabel(\"Partial Dependence\")\n",
    "            ax.xaxis.label.set_size(FS_LABEL)\n",
    "            ax.yaxis.label.set_size(FS_LABEL)\n",
    "            ax.tick_params(axis='both', labelsize=FS_TICKS)\n",
    "            # optional: add a bit of padding to labels\n",
    "            ax.xaxis.labelpad = 12\n",
    "            ax.yaxis.labelpad = 12\n",
    "\n",
    "            ax.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "            # Secondary y-axis histogram (no label)\n",
    "            ax2 = ax.twinx()\n",
    "            vals = X_imp[feat].values\n",
    "            ax2.hist(vals[~np.isnan(vals)], bins=HIST_BINS,\n",
    "                     alpha=HIST_ALPHA, color=HIST_COLOR)\n",
    "            ax2.set_yticks([])\n",
    "            ax2.set_ylabel(\"\")            # no label\n",
    "            ax2.tick_params(axis='both', length=0)\n",
    "            ax2.grid(False)\n",
    "            ax2.set_zorder(1)\n",
    "            ax.set_zorder(2)\n",
    "            ax.patch.set_visible(False)\n",
    "        else:\n",
    "            ax.axis('off')\n",
    "\n",
    "    pretty = {\n",
    "        'above.carbon.combusted': 'Aboveground Carbon',\n",
    "        'below.ground.carbon.combusted': 'Belowground Carbon',\n",
    "        'burn.depth': 'Burn Depth'\n",
    "    }[target]\n",
    "    fig.suptitle(f'New Data ‚Äî Top 6 PDPs ({pretty})', fontsize=FS_SUPTITLE, y=0.98)\n",
    "\n",
    "    save_path = os.path.join(OUT_DIRS[target], f\"pdp_new_{target.replace('.', '_')}_3x2.png\")\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plt.savefig(save_path, dpi=150)\n",
    "    plt.close(fig)\n",
    "\n",
    "print(f\"\\n{'='*70}\\nüéâ Done. Axis labels are now force-sized after PDP draws.\\n{'='*70}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de5c1aff-72e1-47f3-a7d8-234e5ba87f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üöÄ STARTING PDP (New Data only)\n",
      "======================================================================\n",
      "New Data rows: 867\n",
      "\n",
      "‚Äî Target: above.carbon.combusted\n",
      "  ‚úì Trained RF (n=867) on renamed columns\n",
      "\n",
      "‚Äî Target: below.ground.carbon.combusted\n",
      "  ‚úì Trained RF (n=867) on renamed columns\n",
      "\n",
      "‚Äî Target: burn.depth\n",
      "  ‚úì Trained RF (n=866) on renamed columns\n",
      "\n",
      "======================================================================\n",
      "üéâ Done. Column names are renamed in pandas, so plots use pretty labels.\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "# -------------------- Font/Style: force larger text everywhere --------------------\n",
    "FS_SUPTITLE = 36   # figure title\n",
    "FS_LABEL    = 26   # x/y axis labels\n",
    "FS_TICKS    = 22   # tick labels\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"font.size\": FS_TICKS,           # base font size\n",
    "    \"axes.titlesize\": FS_SUPTITLE,   # not used (no subplot titles), but safe\n",
    "    \"axes.labelsize\": FS_LABEL,      # default axis-label size\n",
    "    \"xtick.labelsize\": FS_TICKS,\n",
    "    \"ytick.labelsize\": FS_TICKS,\n",
    "    \"legend.fontsize\": FS_TICKS,\n",
    "})\n",
    "\n",
    "# -------------------- Config --------------------\n",
    "INPUT_CSV = \"/explore/nobackup/people/spotter5/new_combustion/2025-08-13_LC_FISL_Original_combustionModelPredictors.csv\"\n",
    "OLD_PREDICTORS_CSV = \"/explore/nobackup/people/spotter5/new_combustion/Combustion_SynthesisData_05042018_XJW.csv\"\n",
    "BASE_OUT_PATH = \"/explore/nobackup/people/spotter5/new_combustion\"\n",
    "\n",
    "OUT_DIRS = {\n",
    "    'above.carbon.combusted': os.path.join(BASE_OUT_PATH, \"pdp_aboveground_fisl\"),\n",
    "    'below.ground.carbon.combusted': os.path.join(BASE_OUT_PATH, \"pdp_belowground_fisl\"),\n",
    "    'burn.depth': os.path.join(BASE_OUT_PATH, \"pdp_depth_fisl\"),\n",
    "}\n",
    "\n",
    "# Excluded predictor columns\n",
    "POTENTIAL_TARGETS = ['below.ground.carbon.combusted', 'above.carbon.combusted', 'burn.depth']\n",
    "METADATA_COLUMNS = ['burn_year','project.name','latitude','longitude','Date','id','CNA_MAR',\n",
    "                    'fireYr','lat','lon','project_name']\n",
    "COLS_TO_DROP_FROM_X = POTENTIAL_TARGETS + METADATA_COLUMNS\n",
    "\n",
    "# Top-6 features per target (ORIGINAL column names)\n",
    "TOP6 = {\n",
    "    'above.carbon.combusted': ['BS','twi','brightness','ISI','Tree.cover','Temperature'],\n",
    "    'below.ground.carbon.combusted': ['BUI','twi','CNA_PAS','Silt_30','brightness','NV'],\n",
    "    'burn.depth': ['BUI','twi','CNA_PAS','CNA_DD_0','WS','DC'],\n",
    "}\n",
    "\n",
    "# Pretty replacements for axis/feature names (map ORIGINAL -> PRETTY)\n",
    "PRETTY_LABELS = {\n",
    "    'BS': 'Black Spruce',\n",
    "    'twi': 'Topographic Wetness Index',\n",
    "    'brightness': 'Brightness',\n",
    "    'ISI': 'Initial Spread Index',\n",
    "    'Tree.cover': 'Tree Cover (%)',\n",
    "    'Temperature': 'Temperature (¬∞C)',\n",
    "    'BUI': 'Build Up Index',\n",
    "    'CNA_PAS': 'Precipitation as Snow',\n",
    "    'Silt_30': 'Silt %)',\n",
    "    'NV': 'Non-Vegetation Cover (%)',\n",
    "    'CNA_DD_0': 'Degree-Days < 0',\n",
    "    'WS': 'White Spruce',\n",
    "    'DC': 'Drought Code',\n",
    "    # add more mappings as needed\n",
    "}\n",
    "\n",
    "# Plot style\n",
    "HIST_BINS  = 40\n",
    "HIST_ALPHA = 0.30\n",
    "HIST_COLOR = 'skyblue'\n",
    "\n",
    "# -------------------- Helpers --------------------\n",
    "def normalize_name(s):\n",
    "    return \"\".join(ch for ch in str(s).lower() if ch.isalnum())\n",
    "\n",
    "def map_requested_features_to_columns(requested, df_columns):\n",
    "    norm_map = {normalize_name(c): c for c in df_columns}\n",
    "    mapped, missing = [], []\n",
    "    for r in requested:\n",
    "        key = normalize_name(r)\n",
    "        if key in norm_map:\n",
    "            mapped.append(norm_map[key])\n",
    "        else:\n",
    "            missing.append(r)\n",
    "    return mapped, missing\n",
    "\n",
    "def median_impute_numeric(df):\n",
    "    out = df.copy()\n",
    "    num_cols = out.select_dtypes(include=[np.number]).columns\n",
    "    out[num_cols] = out[num_cols].fillna(out[num_cols].median())\n",
    "    return out\n",
    "\n",
    "# -------------------- Load and split --------------------\n",
    "print(f\"\\n{'='*70}\\nüöÄ STARTING PDP (New Data only)\\n{'='*70}\")\n",
    "df_main = pd.read_csv(INPUT_CSV)\n",
    "df_old  = pd.read_csv(OLD_PREDICTORS_CSV)\n",
    "\n",
    "if 'id' not in df_main.columns or 'id' not in df_old.columns:\n",
    "    raise SystemExit(\"‚ùå Both files must have an 'id' column.\")\n",
    "\n",
    "old_ids = pd.unique(df_old['id'])\n",
    "df_new  = df_main[~df_main['id'].isin(old_ids)].copy()\n",
    "print(f\"New Data rows: {len(df_new)}\")\n",
    "\n",
    "# -------------------- Train & plot --------------------\n",
    "for target in OUT_DIRS:\n",
    "    os.makedirs(OUT_DIRS[target], exist_ok=True)\n",
    "    print(f\"\\n‚Äî Target: {target}\")\n",
    "\n",
    "    if target not in df_new.columns:\n",
    "        print(f\"  ‚ö†Ô∏è Target '{target}' not found. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    df_t = df_new.dropna(subset=[target]).copy()\n",
    "    if df_t.empty:\n",
    "        print(f\"  ‚ö†Ô∏è No rows with non-NA '{target}'. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Numeric predictors only, excluding meta/targets\n",
    "    X = df_t.drop(columns=COLS_TO_DROP_FROM_X, errors='ignore').select_dtypes(include=[np.number])\n",
    "    if X.shape[1] == 0:\n",
    "        print(\"  ‚ö†Ô∏è No numeric predictors after exclusions. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # ---- RENAME COLUMNS IN THE DATAFRAME TO PRETTY LABELS (forces PDP to use them) ----\n",
    "    rename_map = {k: v for k, v in PRETTY_LABELS.items() if k in X.columns}\n",
    "    X_renamed = X.rename(columns=rename_map)\n",
    "\n",
    "    # Impute and set target\n",
    "    X_imp = median_impute_numeric(X_renamed)\n",
    "    y = df_t[target].astype(float)\n",
    "\n",
    "    # Train model on the RENAMED feature set\n",
    "    rf = RandomForestRegressor(\n",
    "        n_estimators=500,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        oob_score=len(y) > 10\n",
    "    )\n",
    "    rf.fit(X_imp, y)\n",
    "    print(f\"  ‚úì Trained RF (n={len(y)}) on renamed columns\")\n",
    "\n",
    "    # Use pretty names for requested features so they match the renamed columns\n",
    "    requested = TOP6[target]\n",
    "    requested_pretty = [PRETTY_LABELS.get(r, r) for r in requested]\n",
    "    mapped, missing = map_requested_features_to_columns(requested_pretty, X_imp.columns)\n",
    "    if not mapped:\n",
    "        print(f\"  ‚ö†Ô∏è No requested features found after renaming. Missing: {missing}\")\n",
    "        continue\n",
    "    if missing:\n",
    "        print(f\"  ‚ÑπÔ∏è Some requested features not found after renaming: {missing}\")\n",
    "\n",
    "    fig, axes = plt.subplots(3, 2, figsize=(22, 26))\n",
    "    axes = axes.ravel()\n",
    "\n",
    "    for i in range(6):\n",
    "        ax = axes[i]\n",
    "        if i < len(mapped):\n",
    "            feat = mapped[i]  # this is the PRETTY column name now\n",
    "            try:\n",
    "                PartialDependenceDisplay.from_estimator(\n",
    "                    rf, X_imp, [feat], ax=ax,\n",
    "                    line_kw={\"linewidth\": 4, \"color\": \"black\"}\n",
    "                )\n",
    "            except Exception as e:\n",
    "                ax.text(0.5, 0.5, f\"PDP failed\\n{feat}\\n{e}\",\n",
    "                        ha='center', va='center', fontsize=FS_LABEL, color='red')\n",
    "                ax.axis('off')\n",
    "                continue\n",
    "\n",
    "            # Bigger axes labels (now already pretty)\n",
    "            ax.set_xlabel(feat)  # pretty feature name\n",
    "            ax.set_ylabel(\"Partial Dependence\")\n",
    "            ax.xaxis.label.set_size(FS_LABEL)\n",
    "            ax.yaxis.label.set_size(FS_LABEL)\n",
    "            ax.tick_params(axis='both', labelsize=FS_TICKS)\n",
    "            ax.xaxis.labelpad = 12\n",
    "            ax.yaxis.labelpad = 12\n",
    "            ax.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "            # Secondary y-axis histogram (matching the renamed column)\n",
    "            ax2 = ax.twinx()\n",
    "            vals = X_imp[feat].values\n",
    "            ax2.hist(vals[~np.isnan(vals)], bins=HIST_BINS,\n",
    "                     alpha=HIST_ALPHA, color=HIST_COLOR)\n",
    "            ax2.set_yticks([])\n",
    "            ax2.set_ylabel(\"\")            # no label\n",
    "            ax2.tick_params(axis='both', length=0)\n",
    "            ax2.grid(False)\n",
    "            ax2.set_zorder(1)\n",
    "            ax.set_zorder(2)\n",
    "            ax.patch.set_visible(False)\n",
    "        else:\n",
    "            ax.axis('off')\n",
    "\n",
    "    pretty = {\n",
    "        'above.carbon.combusted': 'Aboveground Carbon',\n",
    "        'below.ground.carbon.combusted': 'Belowground Carbon',\n",
    "        'burn.depth': 'Burn Depth'\n",
    "    }[target]\n",
    "    fig.suptitle(f'New Data ‚Äî Top 6 PDPs ({pretty})', fontsize=FS_SUPTITLE, y=0.98)\n",
    "\n",
    "    save_path = os.path.join(OUT_DIRS[target], f\"pdp_new_{target.replace('.', '_')}_3x2.png\")\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plt.savefig(save_path, dpi=150)\n",
    "    plt.close(fig)\n",
    "\n",
    "print(f\"\\n{'='*70}\\nüéâ Done. Column names are renamed in pandas, so plots use pretty labels.\\n{'='*70}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a6383b-f6cb-4725-872e-7ffd21029104",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-xgboost_gpu]",
   "language": "python",
   "name": "conda-env-.conda-xgboost_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
