{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73d15728-62fe-4eb8-9534-374d503066a8",
   "metadata": {},
   "source": [
    "above ground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04323356-6970-436c-9b78-867a514d14ba",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# 1. Load and clean data\n",
    "df = pd.read_csv(\"/explore/nobackup/people/spotter5/new_combustion/2025-08-13_LC_FISL_Original_combustionModelPredictors.csv\")\n",
    "\n",
    "out_path = \"/explore/nobackup/people/spotter5/new_combustion/all_data\"\n",
    "os.makedirs(out_path, exist_ok = True)\n",
    "\n",
    "# 2. Exclude columns not relevant for modeling\n",
    "exclude_columns = [\n",
    "    #'below.ground.carbon.combusted',\n",
    "    'above.carbon.combusted'\n",
    "    'burn.depth',\n",
    "    'burn_year',\n",
    "    #'rdnbr_old',\n",
    "    'project.name',\n",
    "    'latitude',\n",
    "    'longitude',\n",
    "    'Date',\n",
    "    'id',\n",
    "    'CNA_MAR'\n",
    "    #  'fireYr',\n",
    "    # 'lat',\n",
    "    # 'lon',\n",
    "    # 'project_name'\n",
    "]\n",
    "\n",
    "# 3. Drop excluded columns and NaNs\n",
    "all_data = df.drop(columns=exclude_columns).dropna()\n",
    "\n",
    "\n",
    "# 1. Load and clean data\n",
    "df = pd.read_csv(\"/explore/nobackup/people/spotter5/new_combustion/2025-08-08_LC_FISL_Original_combustionModelPredictors.csv\")\n",
    "\n",
    "old = pd.read_csv(\"/explore/nobackup/people/spotter5/new_combustion/all_predictors.csv\")\n",
    "\n",
    "# Get the unique IDs to remove\n",
    "old_ids = old['id'].unique()\n",
    "\n",
    "# Filter the DataFrame using the ~ operator ✅\n",
    "new_data = df[~df['id'].isin(old_ids)].drop(columns=exclude_columns).dropna()\n",
    "\n",
    "# 1. Load and clean data\n",
    "df = pd.read_csv(\"/explore/nobackup/people/spotter5/new_combustion/2025-08-08_LC_FISL_Original_combustionModelPredictors.csv\")\n",
    "\n",
    "old = pd.read_csv(\"/explore/nobackup/people/spotter5/new_combustion/all_predictors.csv\")\n",
    "\n",
    "# Get the unique IDs to remove\n",
    "old_ids = old['id'].unique()\n",
    "\n",
    "# Filter the DataFrame using the ~ operator ✅\n",
    "old_data = df[df['id'].isin(old_ids)].drop(columns=exclude_columns).dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f465b533-6859-43fa-839a-eed505c8c61c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "🚀 STARTING ANALYSIS | TARGET: 'below.ground.carbon.combusted'\n",
      "======================================================================\n",
      "Step 1: Loading and preparing data...\n",
      "Step 2: Training Random Forest models on 'below.ground.carbon.combusted'...\n",
      "  - Training on 'All Data' (1877 rows)...\n",
      "    ...Done. Model OOB Score (R²): 0.434\n",
      "  - Training on 'Old Data' (1010 rows)...\n",
      "    ...Done. Model OOB Score (R²): 0.228\n",
      "  - Training on 'New Data' (867 rows)...\n",
      "    ...Done. Model OOB Score (R²): 0.607\n",
      "\n",
      "Step 3: Generating 78 Partial Dependence Plots...\n",
      "  - Plotting for: PFI\n",
      "  - Plotting for: pH_30\n",
      "  - Plotting for: Sand_30\n",
      "  - Plotting for: Silt_30\n",
      "  - Plotting for: Clay_30\n",
      "  - Plotting for: DOB_lst\n",
      "  - Plotting for: Relative.humidity\n",
      "  - Plotting for: Temperature\n",
      "  - Plotting for: VPD\n",
      "  - Plotting for: Wind.speed\n",
      "  - Plotting for: JP\n",
      "  - Plotting for: BS\n",
      "  - Plotting for: DEC\n",
      "  - Plotting for: GRSH\n",
      "  - Plotting for: NV\n",
      "  - Plotting for: OCON\n",
      "  - Plotting for: WS\n",
      "  - Plotting for: CNA_Tmax_5_8\n",
      "  - Plotting for: CNA_PPT_5_8\n",
      "  - Plotting for: CNA_Rad_5_8\n",
      "  - Plotting for: CNA_DD_0_5_8\n",
      "  - Plotting for: CNA_DD5_5_8\n",
      "  - Plotting for: CNA_DD_18_5_8\n",
      "  - Plotting for: CNA_DD18_sm\n",
      "  - Plotting for: CNA_NFFD_5_8\n",
      "  - Plotting for: CNA_PAS_5_8\n",
      "  - Plotting for: CNA_Eref_5_8\n",
      "  - Plotting for: CNA_CMD_5_8\n",
      "  - Plotting for: CNA_RH_5_8\n",
      "  - Plotting for: CNA_Tave_5_8\n",
      "  - Plotting for: CNA_Tmin_5_8\n",
      "  - Plotting for: CNA_MAT\n",
      "  - Plotting for: CNA_MWMT\n",
      "  - Plotting for: CNA_MCMT\n",
      "  - Plotting for: CNA_TD\n",
      "  - Plotting for: CNA_MAP\n",
      "  - Plotting for: CNA_MSP\n",
      "  - Plotting for: CNA_AHM\n",
      "  - Plotting for: CNA_SHM\n",
      "  - Plotting for: CNA_DD_0\n",
      "  - Plotting for: CNA_DD5\n",
      "  - Plotting for: CNA_DD_18\n",
      "  - Plotting for: CNA_DD18\n",
      "  - Plotting for: CNA_NFFD\n",
      "  - Plotting for: CNA_bFFP\n",
      "  - Plotting for: CNA_eFFP\n",
      "  - Plotting for: CNA_FFP\n",
      "  - Plotting for: CNA_PAS\n",
      "  - Plotting for: CNA_EMT\n",
      "  - Plotting for: CNA_EXT\n",
      "  - Plotting for: CNA_Eref\n",
      "  - Plotting for: CNA_CMD\n",
      "  - Plotting for: CNA_RH\n",
      "  - Plotting for: BD_30\n",
      "  - Plotting for: NDII\n",
      "  - Plotting for: NDVI\n",
      "  - Plotting for: SOC_30\n",
      "  - Plotting for: brightness\n",
      "  - Plotting for: dNBR\n",
      "  - Plotting for: greenness\n",
      "  - Plotting for: rbr\n",
      "  - Plotting for: Tree.cover\n",
      "  - Plotting for: wetness\n",
      "  - Plotting for: rdnbr\n",
      "  - Plotting for: BUI\n",
      "  - Plotting for: DC\n",
      "  - Plotting for: DMC\n",
      "  - Plotting for: FFMC\n",
      "  - Plotting for: FWI\n",
      "  - Plotting for: ISI\n",
      "  - Plotting for: DSR\n",
      "  - Plotting for: elevation\n",
      "  - Plotting for: twi\n",
      "  - Plotting for: HLI\n",
      "  - Plotting for: TRASP\n",
      "  - Plotting for: aspect_rad\n",
      "  - Plotting for: slope_rad\n",
      "  - Plotting for: ruggedness\n",
      "\n",
      "✅ ANALYSIS COMPLETE for 'below.ground.carbon.combusted'. Plots saved to: /explore/nobackup/people/spotter5/new_combustion/pdp_belowground\n",
      "\n",
      "======================================================================\n",
      "🚀 STARTING ANALYSIS | TARGET: 'above.carbon.combusted'\n",
      "======================================================================\n",
      "Step 1: Loading and preparing data...\n",
      "Step 2: Training Random Forest models on 'above.carbon.combusted'...\n",
      "  - Training on 'All Data' (1877 rows)...\n",
      "    ...Done. Model OOB Score (R²): 0.421\n",
      "  - Training on 'Old Data' (1010 rows)...\n",
      "    ...Done. Model OOB Score (R²): 0.339\n",
      "  - Training on 'New Data' (867 rows)...\n",
      "    ...Done. Model OOB Score (R²): 0.411\n",
      "\n",
      "Step 3: Generating 78 Partial Dependence Plots...\n",
      "  - Plotting for: PFI\n",
      "  - Plotting for: pH_30\n",
      "  - Plotting for: Sand_30\n",
      "  - Plotting for: Silt_30\n",
      "  - Plotting for: Clay_30\n",
      "  - Plotting for: DOB_lst\n",
      "  - Plotting for: Relative.humidity\n",
      "  - Plotting for: Temperature\n",
      "  - Plotting for: VPD\n",
      "  - Plotting for: Wind.speed\n",
      "  - Plotting for: JP\n",
      "  - Plotting for: BS\n",
      "  - Plotting for: DEC\n",
      "  - Plotting for: GRSH\n",
      "  - Plotting for: NV\n",
      "  - Plotting for: OCON\n",
      "  - Plotting for: WS\n",
      "  - Plotting for: CNA_Tmax_5_8\n",
      "  - Plotting for: CNA_PPT_5_8\n",
      "  - Plotting for: CNA_Rad_5_8\n",
      "  - Plotting for: CNA_DD_0_5_8\n",
      "  - Plotting for: CNA_DD5_5_8\n",
      "  - Plotting for: CNA_DD_18_5_8\n",
      "  - Plotting for: CNA_DD18_sm\n",
      "  - Plotting for: CNA_NFFD_5_8\n",
      "  - Plotting for: CNA_PAS_5_8\n",
      "  - Plotting for: CNA_Eref_5_8\n",
      "  - Plotting for: CNA_CMD_5_8\n",
      "  - Plotting for: CNA_RH_5_8\n",
      "  - Plotting for: CNA_Tave_5_8\n",
      "  - Plotting for: CNA_Tmin_5_8\n",
      "  - Plotting for: CNA_MAT\n",
      "  - Plotting for: CNA_MWMT\n",
      "  - Plotting for: CNA_MCMT\n",
      "  - Plotting for: CNA_TD\n",
      "  - Plotting for: CNA_MAP\n",
      "  - Plotting for: CNA_MSP\n",
      "  - Plotting for: CNA_AHM\n",
      "  - Plotting for: CNA_SHM\n",
      "  - Plotting for: CNA_DD_0\n",
      "  - Plotting for: CNA_DD5\n",
      "  - Plotting for: CNA_DD_18\n",
      "  - Plotting for: CNA_DD18\n",
      "  - Plotting for: CNA_NFFD\n",
      "  - Plotting for: CNA_bFFP\n",
      "  - Plotting for: CNA_eFFP\n",
      "  - Plotting for: CNA_FFP\n",
      "  - Plotting for: CNA_PAS\n",
      "  - Plotting for: CNA_EMT\n",
      "  - Plotting for: CNA_EXT\n",
      "  - Plotting for: CNA_Eref\n",
      "  - Plotting for: CNA_CMD\n",
      "  - Plotting for: CNA_RH\n",
      "  - Plotting for: BD_30\n",
      "  - Plotting for: NDII\n",
      "  - Plotting for: NDVI\n",
      "  - Plotting for: SOC_30\n",
      "  - Plotting for: brightness\n",
      "  - Plotting for: dNBR\n",
      "  - Plotting for: greenness\n",
      "  - Plotting for: rbr\n",
      "  - Plotting for: Tree.cover\n",
      "  - Plotting for: wetness\n",
      "  - Plotting for: rdnbr\n",
      "  - Plotting for: BUI\n",
      "  - Plotting for: DC\n",
      "  - Plotting for: DMC\n",
      "  - Plotting for: FFMC\n",
      "  - Plotting for: FWI\n",
      "  - Plotting for: ISI\n",
      "  - Plotting for: DSR\n",
      "  - Plotting for: elevation\n",
      "  - Plotting for: twi\n",
      "  - Plotting for: HLI\n",
      "  - Plotting for: TRASP\n",
      "  - Plotting for: aspect_rad\n",
      "  - Plotting for: slope_rad\n",
      "  - Plotting for: ruggedness\n",
      "\n",
      "✅ ANALYSIS COMPLETE for 'above.carbon.combusted'. Plots saved to: /explore/nobackup/people/spotter5/new_combustion/pdp_aboveground\n",
      "\n",
      "======================================================================\n",
      "🚀 STARTING ANALYSIS | TARGET: 'burn.depth'\n",
      "======================================================================\n",
      "Step 1: Loading and preparing data...\n",
      "Step 2: Training Random Forest models on 'burn.depth'...\n",
      "  - Training on 'All Data' (1877 rows)...\n",
      "    ...Done. Model OOB Score (R²): 0.690\n",
      "  - Training on 'Old Data' (1010 rows)...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 78)) while a minimum of 1 is required by RandomForestRegressor.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 123\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;66;03m# Execute each analysis\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m target_col, out_dir \u001b[38;5;129;01min\u001b[39;00m analyses\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 123\u001b[0m     \u001b[43mrun_pdp_analysis\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_variable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_csv_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mINPUT_CSV\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m        \u001b[49m\u001b[43mold_ids_csv_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mOLD_PREDICTORS_CSV\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m70\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m🎉 All tasks finished.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 72\u001b[0m, in \u001b[0;36mrun_pdp_analysis\u001b[0;34m(target_variable, output_directory, input_csv_path, old_ids_csv_path)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# Initialize and train the model\u001b[39;00m\n\u001b[1;32m     71\u001b[0m rf \u001b[38;5;241m=\u001b[39m RandomForestRegressor(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, oob_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 72\u001b[0m \u001b[43mrf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    ...Done. Model OOB Score (R²): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrf\u001b[38;5;241m.\u001b[39moob_score_\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# Store the trained model and predictor data\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/xgboost_gpu/lib/python3.9/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/xgboost_gpu/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:363\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(y):\n\u001b[1;32m    361\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse multilabel-indicator for y is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 363\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;66;03m# _compute_missing_values_in_feature_mask checks if X has missing values and\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;66;03m# will raise an error if the underlying tree base estimator can't handle missing\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;66;03m# values. Only the criterion is required to determine if the tree supports\u001b[39;00m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;66;03m# missing values.\u001b[39;00m\n\u001b[1;32m    375\u001b[0m estimator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator)(criterion\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion)\n",
      "File \u001b[0;32m~/.conda/envs/xgboost_gpu/lib/python3.9/site-packages/sklearn/base.py:650\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    648\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m    649\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 650\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/.conda/envs/xgboost_gpu/lib/python3.9/site-packages/sklearn/utils/validation.py:1301\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1296\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[1;32m   1297\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1298\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1299\u001b[0m     )\n\u001b[0;32m-> 1301\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1302\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1303\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1304\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1305\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1306\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1307\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1308\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_writeable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1309\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1310\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1313\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1315\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1316\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1318\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[1;32m   1320\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m~/.conda/envs/xgboost_gpu/lib/python3.9/site-packages/sklearn/utils/validation.py:1087\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1085\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n\u001b[1;32m   1086\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_samples \u001b[38;5;241m<\u001b[39m ensure_min_samples:\n\u001b[0;32m-> 1087\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1088\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m sample(s) (shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) while a\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1089\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m minimum of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m is required\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1090\u001b[0m             \u001b[38;5;241m%\u001b[39m (n_samples, array\u001b[38;5;241m.\u001b[39mshape, ensure_min_samples, context)\n\u001b[1;32m   1091\u001b[0m         )\n\u001b[1;32m   1093\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_features \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m   1094\u001b[0m     n_features \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 78)) while a minimum of 1 is required by RandomForestRegressor."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "def run_pdp_analysis(target_variable, output_directory, input_csv_path, old_ids_csv_path):\n",
    "    \"\"\"\n",
    "    Runs the full modeling and PDP generation pipeline for a specific target variable.\n",
    "\n",
    "    Args:\n",
    "        target_variable (str): The name of the column to use as the target.\n",
    "        output_directory (str): The path to save the generated PDP images.\n",
    "        input_csv_path (str): Path to the main input CSV file.\n",
    "        old_ids_csv_path (str): Path to the CSV containing old plot IDs.\n",
    "    \"\"\"\n",
    "    # --- Setup & Introduction ---\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"🚀 STARTING ANALYSIS | TARGET: '{target_variable}'\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "    warnings.filterwarnings('ignore', category=UserWarning)\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "    # --- 1. Data Preparation ---\n",
    "    print(\"Step 1: Loading and preparing data...\")\n",
    "    try:\n",
    "        df_main = pd.read_csv(input_csv_path)\n",
    "        df_old_ids = pd.read_csv(old_ids_csv_path)\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"❌ Error: Could not find input file. {e}\")\n",
    "        return\n",
    "\n",
    "    # Define columns to exclude from predictors.\n",
    "    # CRITICAL: We must exclude BOTH potential target variables from the predictors\n",
    "    # to prevent data leakage between the two analyses.\n",
    "    POTENTIAL_TARGETS = ['below.ground.carbon.combusted', 'above.carbon.combusted', 'burn.depth']\n",
    "    METADATA_COLUMNS = [\n",
    "        'burn_year', 'project.name', 'latitude', 'longitude', 'Date', 'id',\n",
    "        'CNA_MAR'\n",
    "    ]\n",
    "    \n",
    "    # Combine all columns to be dropped when creating the predictor set (X)\n",
    "    COLS_TO_DROP_FROM_X = POTENTIAL_TARGETS + METADATA_COLUMNS\n",
    "\n",
    "    # Prepare the three datasets (All, Old, New)\n",
    "    old_ids = df_old_ids['id'].unique()\n",
    "    data_splits = {\n",
    "        \"All Data\": df_main,\n",
    "        \"Old Data\": df_main[df_main['id'].isin(old_ids)],\n",
    "        \"New Data\": df_main[~df_main['id'].isin(old_ids)]\n",
    "    }\n",
    "\n",
    "    # --- 2. Model Training ---\n",
    "    print(f\"Step 2: Training Random Forest models on '{target_variable}'...\")\n",
    "    models = {}\n",
    "    for name, data in data_splits.items():\n",
    "        print(f\"  - Training on '{name}' ({len(data)} rows)...\")\n",
    "\n",
    "        # Drop rows where the CURRENT target variable is missing\n",
    "        df_clean = data.dropna(subset=[target_variable])\n",
    "\n",
    "        # Define predictors (X) and target (y)\n",
    "        X = df_clean.drop(columns=COLS_TO_DROP_FROM_X, errors='ignore')\n",
    "        y = df_clean[target_variable]\n",
    "\n",
    "        # Initialize and train the model\n",
    "        rf = RandomForestRegressor(n_estimators=500, random_state=42, n_jobs=-1, oob_score=True)\n",
    "        rf.fit(X, y)\n",
    "        print(f\"    ...Done. Model OOB Score (R²): {rf.oob_score_:.3f}\")\n",
    "\n",
    "        # Store the trained model and predictor data\n",
    "        models[name] = {'model': rf, 'X': X}\n",
    "\n",
    "    # --- 3. Generate and Save Partial Dependence Plots ---\n",
    "    feature_list = models['All Data']['X'].columns\n",
    "    print(f\"\\nStep 3: Generating {len(feature_list)} Partial Dependence Plots...\")\n",
    "\n",
    "    for feature in feature_list:\n",
    "        print(f\"  - Plotting for: {feature}\")\n",
    "        fig, axes = plt.subplots(3, 1, figsize=(8, 12), sharex=True)\n",
    "        fig.suptitle(f'Partial Dependence on: {feature}\\n(Target: {target_variable})', fontsize=16, y=0.96)\n",
    "\n",
    "        plot_order = [\"All Data\", \"Old Data\", \"New Data\"]\n",
    "        for i, model_name in enumerate(plot_order):\n",
    "            ax = axes[i]\n",
    "            model_info = models[model_name]\n",
    "            PartialDependenceDisplay.from_estimator(\n",
    "                estimator=model_info['model'], X=model_info['X'], features=[feature],\n",
    "                ax=ax, line_kw={\"color\": \"darkcyan\", \"linewidth\": 2.5}\n",
    "            )\n",
    "            ax.set_title(f\"{model_name} (n={len(model_info['X'])})\")\n",
    "            ax.set_ylabel(\"Partial Dependence\")\n",
    "            ax.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "        save_path = os.path.join(output_directory, f'{feature}.png')\n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.94])\n",
    "        plt.savefig(save_path)\n",
    "        plt.close(fig)\n",
    "\n",
    "    print(f\"\\n✅ ANALYSIS COMPLETE for '{target_variable}'. Plots saved to: {output_directory}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # --- Master Configuration ---\n",
    "    INPUT_CSV = \"/explore/nobackup/people/spotter5/new_combustion/2025-08-13_LC_FISL_Original_combustionModelPredictors.csv\"\n",
    "    # OLD_PREDICTORS_CSV = \"/explore/nobackup/people/spotter5/new_combustion/all_predictors.csv\"\n",
    "    OLD_PREDICTORS_CSV = \"/explore/nobackup/people/spotter5/new_combustion/Combustion_SynthesisData_05042018_XJW.csv\"\n",
    "    BASE_OUT_PATH = \"/explore/nobackup/people/spotter5/new_combustion\"\n",
    "\n",
    "    # Define the analyses to run\n",
    "    analyses = {\n",
    "        'below.ground.carbon.combusted': os.path.join(BASE_OUT_PATH, \"pdp_belowground\"),\n",
    "        'above.carbon.combusted': os.path.join(BASE_OUT_PATH, \"pdp_aboveground\"),\n",
    "        'burn.depth': os.path.join(BASE_OUT_PATH, \"pdp_depth\")\n",
    "    }\n",
    "\n",
    "    # Execute each analysis\n",
    "    for target_col, out_dir in analyses.items():\n",
    "        run_pdp_analysis(\n",
    "            target_variable=target_col,\n",
    "            output_directory=out_dir,\n",
    "            input_csv_path=INPUT_CSV,\n",
    "            old_ids_csv_path=OLD_PREDICTORS_CSV\n",
    "        )\n",
    "\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"🎉 All tasks finished.\")\n",
    "    print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f101ec83-4516-4525-a0f3-eb62319bb17e",
   "metadata": {},
   "source": [
    "With depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d75b8fb-a039-4d1e-8cd6-bcc7f61945b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "🚀 STARTING ANALYSIS | TARGET: 'below.ground.carbon.combusted'\n",
      "======================================================================\n",
      "Step 1: Loading and preparing data...\n",
      "Step 2: Training Random Forest models on 'below.ground.carbon.combusted'...\n",
      "  - Training on 'All Data' (1877 rows)...\n",
      "    ...Done. Model OOB Score (R²): 0.434\n",
      "  - Training on 'Old Data' (1010 rows)...\n",
      "    ...Done. Model OOB Score (R²): 0.226\n",
      "  - Training on 'New Data' (867 rows)...\n",
      "    ...Done. Model OOB Score (R²): 0.607\n",
      "\n",
      "Step 3: Generating 78 Partial Dependence Plots...\n",
      "  - Plotting for: PFI\n",
      "  - Plotting for: pH_30\n",
      "  - Plotting for: Sand_30\n",
      "  - Plotting for: Silt_30\n",
      "  - Plotting for: Clay_30\n",
      "  - Plotting for: DOB_lst\n",
      "  - Plotting for: Relative.humidity\n",
      "  - Plotting for: Temperature\n",
      "  - Plotting for: VPD\n",
      "  - Plotting for: Wind.speed\n",
      "  - Plotting for: JP\n",
      "  - Plotting for: BS\n",
      "  - Plotting for: DEC\n",
      "  - Plotting for: GRSH\n",
      "  - Plotting for: NV\n",
      "  - Plotting for: OCON\n",
      "  - Plotting for: WS\n",
      "  - Plotting for: CNA_Tmax_5_8\n",
      "  - Plotting for: CNA_PPT_5_8\n",
      "  - Plotting for: CNA_Rad_5_8\n",
      "  - Plotting for: CNA_DD_0_5_8\n",
      "  - Plotting for: CNA_DD5_5_8\n",
      "  - Plotting for: CNA_DD_18_5_8\n",
      "  - Plotting for: CNA_DD18_sm\n",
      "  - Plotting for: CNA_NFFD_5_8\n",
      "  - Plotting for: CNA_PAS_5_8\n",
      "  - Plotting for: CNA_Eref_5_8\n",
      "  - Plotting for: CNA_CMD_5_8\n",
      "  - Plotting for: CNA_RH_5_8\n",
      "  - Plotting for: CNA_Tave_5_8\n",
      "  - Plotting for: CNA_Tmin_5_8\n",
      "  - Plotting for: CNA_MAT\n",
      "  - Plotting for: CNA_MWMT\n",
      "  - Plotting for: CNA_MCMT\n",
      "  - Plotting for: CNA_TD\n",
      "  - Plotting for: CNA_MAP\n",
      "  - Plotting for: CNA_MSP\n",
      "  - Plotting for: CNA_AHM\n",
      "  - Plotting for: CNA_SHM\n",
      "  - Plotting for: CNA_DD_0\n",
      "  - Plotting for: CNA_DD5\n",
      "  - Plotting for: CNA_DD_18\n",
      "  - Plotting for: CNA_DD18\n",
      "  - Plotting for: CNA_NFFD\n",
      "  - Plotting for: CNA_bFFP\n",
      "  - Plotting for: CNA_eFFP\n",
      "  - Plotting for: CNA_FFP\n",
      "  - Plotting for: CNA_PAS\n",
      "  - Plotting for: CNA_EMT\n",
      "  - Plotting for: CNA_EXT\n",
      "  - Plotting for: CNA_Eref\n",
      "  - Plotting for: CNA_CMD\n",
      "  - Plotting for: CNA_RH\n",
      "  - Plotting for: BD_30\n",
      "  - Plotting for: NDII\n",
      "  - Plotting for: NDVI\n",
      "  - Plotting for: SOC_30\n",
      "  - Plotting for: brightness\n",
      "  - Plotting for: dNBR\n",
      "  - Plotting for: greenness\n",
      "  - Plotting for: rbr\n",
      "  - Plotting for: Tree.cover\n",
      "  - Plotting for: wetness\n",
      "  - Plotting for: rdnbr\n",
      "  - Plotting for: BUI\n",
      "  - Plotting for: DC\n",
      "  - Plotting for: DMC\n",
      "  - Plotting for: FFMC\n",
      "  - Plotting for: FWI\n",
      "  - Plotting for: ISI\n",
      "  - Plotting for: DSR\n",
      "  - Plotting for: elevation\n",
      "  - Plotting for: twi\n",
      "  - Plotting for: HLI\n",
      "  - Plotting for: TRASP\n",
      "  - Plotting for: aspect_rad\n",
      "  - Plotting for: slope_rad\n",
      "  - Plotting for: ruggedness\n",
      "\n",
      "✅ ANALYSIS COMPLETE for 'below.ground.carbon.combusted'. Plots saved to: /explore/nobackup/people/spotter5/new_combustion/pdp_belowground\n",
      "\n",
      "======================================================================\n",
      "🚀 STARTING ANALYSIS | TARGET: 'above.carbon.combusted'\n",
      "======================================================================\n",
      "Step 1: Loading and preparing data...\n",
      "Step 2: Training Random Forest models on 'above.carbon.combusted'...\n",
      "  - Training on 'All Data' (1877 rows)...\n",
      "    ...Done. Model OOB Score (R²): 0.421\n",
      "  - Training on 'Old Data' (1010 rows)...\n",
      "    ...Done. Model OOB Score (R²): 0.342\n",
      "  - Training on 'New Data' (867 rows)...\n",
      "    ...Done. Model OOB Score (R²): 0.411\n",
      "\n",
      "Step 3: Generating 78 Partial Dependence Plots...\n",
      "  - Plotting for: PFI\n",
      "  - Plotting for: pH_30\n",
      "  - Plotting for: Sand_30\n",
      "  - Plotting for: Silt_30\n",
      "  - Plotting for: Clay_30\n",
      "  - Plotting for: DOB_lst\n",
      "  - Plotting for: Relative.humidity\n",
      "  - Plotting for: Temperature\n",
      "  - Plotting for: VPD\n",
      "  - Plotting for: Wind.speed\n",
      "  - Plotting for: JP\n",
      "  - Plotting for: BS\n",
      "  - Plotting for: DEC\n",
      "  - Plotting for: GRSH\n",
      "  - Plotting for: NV\n",
      "  - Plotting for: OCON\n",
      "  - Plotting for: WS\n",
      "  - Plotting for: CNA_Tmax_5_8\n",
      "  - Plotting for: CNA_PPT_5_8\n",
      "  - Plotting for: CNA_Rad_5_8\n",
      "  - Plotting for: CNA_DD_0_5_8\n",
      "  - Plotting for: CNA_DD5_5_8\n",
      "  - Plotting for: CNA_DD_18_5_8\n",
      "  - Plotting for: CNA_DD18_sm\n",
      "  - Plotting for: CNA_NFFD_5_8\n",
      "  - Plotting for: CNA_PAS_5_8\n",
      "  - Plotting for: CNA_Eref_5_8\n",
      "  - Plotting for: CNA_CMD_5_8\n",
      "  - Plotting for: CNA_RH_5_8\n",
      "  - Plotting for: CNA_Tave_5_8\n",
      "  - Plotting for: CNA_Tmin_5_8\n",
      "  - Plotting for: CNA_MAT\n",
      "  - Plotting for: CNA_MWMT\n",
      "  - Plotting for: CNA_MCMT\n",
      "  - Plotting for: CNA_TD\n",
      "  - Plotting for: CNA_MAP\n",
      "  - Plotting for: CNA_MSP\n",
      "  - Plotting for: CNA_AHM\n",
      "  - Plotting for: CNA_SHM\n",
      "  - Plotting for: CNA_DD_0\n",
      "  - Plotting for: CNA_DD5\n",
      "  - Plotting for: CNA_DD_18\n",
      "  - Plotting for: CNA_DD18\n",
      "  - Plotting for: CNA_NFFD\n",
      "  - Plotting for: CNA_bFFP\n",
      "  - Plotting for: CNA_eFFP\n",
      "  - Plotting for: CNA_FFP\n",
      "  - Plotting for: CNA_PAS\n",
      "  - Plotting for: CNA_EMT\n",
      "  - Plotting for: CNA_EXT\n",
      "  - Plotting for: CNA_Eref\n",
      "  - Plotting for: CNA_CMD\n",
      "  - Plotting for: CNA_RH\n",
      "  - Plotting for: BD_30\n",
      "  - Plotting for: NDII\n",
      "  - Plotting for: NDVI\n",
      "  - Plotting for: SOC_30\n",
      "  - Plotting for: brightness\n",
      "  - Plotting for: dNBR\n",
      "  - Plotting for: greenness\n",
      "  - Plotting for: rbr\n",
      "  - Plotting for: Tree.cover\n",
      "  - Plotting for: wetness\n",
      "  - Plotting for: rdnbr\n",
      "  - Plotting for: BUI\n",
      "  - Plotting for: DC\n",
      "  - Plotting for: DMC\n",
      "  - Plotting for: FFMC\n",
      "  - Plotting for: FWI\n",
      "  - Plotting for: ISI\n",
      "  - Plotting for: DSR\n",
      "  - Plotting for: elevation\n",
      "  - Plotting for: twi\n",
      "  - Plotting for: HLI\n",
      "  - Plotting for: TRASP\n",
      "  - Plotting for: aspect_rad\n",
      "  - Plotting for: slope_rad\n",
      "  - Plotting for: ruggedness\n",
      "\n",
      "✅ ANALYSIS COMPLETE for 'above.carbon.combusted'. Plots saved to: /explore/nobackup/people/spotter5/new_combustion/pdp_aboveground\n",
      "\n",
      "======================================================================\n",
      "🚀 STARTING ANALYSIS | TARGET: 'burn.depth'\n",
      "======================================================================\n",
      "Step 1: Loading and preparing data...\n",
      "  - Backfilling 'burn.depth' from old CSV where missing in main...\n",
      "    Filled 904 missing burn.depth values.\n",
      "Step 2: Training Random Forest models on 'burn.depth'...\n",
      "  - Training on 'All Data' (1877 rows)...\n",
      "    ...Done. Model OOB Score (R²): 0.625\n",
      "  - Training on 'Old Data' (1010 rows)...\n",
      "    ...Done. Model OOB Score (R²): 0.502\n",
      "  - Training on 'New Data' (867 rows)...\n",
      "    ...Done. Model OOB Score (R²): 0.690\n",
      "\n",
      "Step 3: Generating 78 Partial Dependence Plots...\n",
      "  - Plotting for: PFI\n",
      "  - Plotting for: pH_30\n",
      "  - Plotting for: Sand_30\n",
      "  - Plotting for: Silt_30\n",
      "  - Plotting for: Clay_30\n",
      "  - Plotting for: DOB_lst\n",
      "  - Plotting for: Relative.humidity\n",
      "  - Plotting for: Temperature\n",
      "  - Plotting for: VPD\n",
      "  - Plotting for: Wind.speed\n",
      "  - Plotting for: JP\n",
      "  - Plotting for: BS\n",
      "  - Plotting for: DEC\n",
      "  - Plotting for: GRSH\n",
      "  - Plotting for: NV\n",
      "  - Plotting for: OCON\n",
      "  - Plotting for: WS\n",
      "  - Plotting for: CNA_Tmax_5_8\n",
      "  - Plotting for: CNA_PPT_5_8\n",
      "  - Plotting for: CNA_Rad_5_8\n",
      "  - Plotting for: CNA_DD_0_5_8\n",
      "  - Plotting for: CNA_DD5_5_8\n",
      "  - Plotting for: CNA_DD_18_5_8\n",
      "  - Plotting for: CNA_DD18_sm\n",
      "  - Plotting for: CNA_NFFD_5_8\n",
      "  - Plotting for: CNA_PAS_5_8\n",
      "  - Plotting for: CNA_Eref_5_8\n",
      "  - Plotting for: CNA_CMD_5_8\n",
      "  - Plotting for: CNA_RH_5_8\n",
      "  - Plotting for: CNA_Tave_5_8\n",
      "  - Plotting for: CNA_Tmin_5_8\n",
      "  - Plotting for: CNA_MAT\n",
      "  - Plotting for: CNA_MWMT\n",
      "  - Plotting for: CNA_MCMT\n",
      "  - Plotting for: CNA_TD\n",
      "  - Plotting for: CNA_MAP\n",
      "  - Plotting for: CNA_MSP\n",
      "  - Plotting for: CNA_AHM\n",
      "  - Plotting for: CNA_SHM\n",
      "  - Plotting for: CNA_DD_0\n",
      "  - Plotting for: CNA_DD5\n",
      "  - Plotting for: CNA_DD_18\n",
      "  - Plotting for: CNA_DD18\n",
      "  - Plotting for: CNA_NFFD\n",
      "  - Plotting for: CNA_bFFP\n",
      "  - Plotting for: CNA_eFFP\n",
      "  - Plotting for: CNA_FFP\n",
      "  - Plotting for: CNA_PAS\n",
      "  - Plotting for: CNA_EMT\n",
      "  - Plotting for: CNA_EXT\n",
      "  - Plotting for: CNA_Eref\n",
      "  - Plotting for: CNA_CMD\n",
      "  - Plotting for: CNA_RH\n",
      "  - Plotting for: BD_30\n",
      "  - Plotting for: NDII\n",
      "  - Plotting for: NDVI\n",
      "  - Plotting for: SOC_30\n",
      "  - Plotting for: brightness\n",
      "  - Plotting for: dNBR\n",
      "  - Plotting for: greenness\n",
      "  - Plotting for: rbr\n",
      "  - Plotting for: Tree.cover\n",
      "  - Plotting for: wetness\n",
      "  - Plotting for: rdnbr\n",
      "  - Plotting for: BUI\n",
      "  - Plotting for: DC\n",
      "  - Plotting for: DMC\n",
      "  - Plotting for: FFMC\n",
      "  - Plotting for: FWI\n",
      "  - Plotting for: ISI\n",
      "  - Plotting for: DSR\n",
      "  - Plotting for: elevation\n",
      "  - Plotting for: twi\n",
      "  - Plotting for: HLI\n",
      "  - Plotting for: TRASP\n",
      "  - Plotting for: aspect_rad\n",
      "  - Plotting for: slope_rad\n",
      "  - Plotting for: ruggedness\n",
      "\n",
      "✅ ANALYSIS COMPLETE for 'burn.depth'. Plots saved to: /explore/nobackup/people/spotter5/new_combustion/pdp_depth\n",
      "\n",
      "======================================================================\n",
      "🎉 All tasks finished.\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "def run_pdp_analysis(target_variable, output_directory, input_csv_path, old_ids_csv_path):\n",
    "    \"\"\"\n",
    "    Runs the full modeling and PDP generation pipeline for a specific target variable.\n",
    "\n",
    "    Args:\n",
    "        target_variable (str): The name of the column to use as the target.\n",
    "        output_directory (str): The path to save the generated PDP images.\n",
    "        input_csv_path (str): Path to the main input CSV file.\n",
    "        old_ids_csv_path (str): Path to the CSV containing old plot IDs and, if available, burn.depth.\n",
    "    \"\"\"\n",
    "    # --- Setup & Introduction ---\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"🚀 STARTING ANALYSIS | TARGET: '{target_variable}'\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "    warnings.filterwarnings('ignore', category=UserWarning)\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "    # --- 1. Data Preparation ---\n",
    "    print(\"Step 1: Loading and preparing data...\")\n",
    "    try:\n",
    "        df_main = pd.read_csv(input_csv_path)\n",
    "        df_old_ids = pd.read_csv(old_ids_csv_path)\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"❌ Error: Could not find input file. {e}\")\n",
    "        return\n",
    "\n",
    "    # Normalize 'id' types & dedupe\n",
    "    if 'id' not in df_main.columns or 'id' not in df_old_ids.columns:\n",
    "        print(\"❌ Error: Both input files must have an 'id' column.\")\n",
    "        return\n",
    "\n",
    "    for df in (df_main, df_old_ids):\n",
    "        # coerce to numeric if possible (keeps strings if not)\n",
    "        try:\n",
    "            df['id'] = pd.to_numeric(df['id'], errors='ignore')\n",
    "        except Exception:\n",
    "            pass\n",
    "    df_old_ids = df_old_ids.drop_duplicates(subset='id')\n",
    "\n",
    "    # If we're modeling burn.depth, try to backfill from old file (if present there)\n",
    "    if target_variable == 'burn.depth' and 'burn.depth' in df_old_ids.columns:\n",
    "        print(\"  - Backfilling 'burn.depth' from old CSV where missing in main...\")\n",
    "        before_na = df_main['burn.depth'].isna().sum() if 'burn.depth' in df_main.columns else None\n",
    "        if 'burn.depth' not in df_main.columns:\n",
    "            df_main['burn.depth'] = np.nan\n",
    "        df_main = df_main.set_index('id')\n",
    "        df_old_depth = df_old_ids.set_index('id')['burn.depth']\n",
    "        df_main['burn.depth'] = df_main['burn.depth'].combine_first(df_old_depth)\n",
    "        df_main = df_main.reset_index()\n",
    "        after_na = df_main['burn.depth'].isna().sum()\n",
    "        if before_na is not None:\n",
    "            print(f\"    Filled {before_na - after_na} missing burn.depth values.\")\n",
    "\n",
    "    # Define columns to exclude from predictors (X)\n",
    "    POTENTIAL_TARGETS = ['below.ground.carbon.combusted', 'above.carbon.combusted', 'burn.depth']\n",
    "    METADATA_COLUMNS = [\n",
    "        'burn_year', 'project.name', 'latitude', 'longitude', 'Date', 'id', 'CNA_MAR'\n",
    "    ]\n",
    "    COLS_TO_DROP_FROM_X = POTENTIAL_TARGETS + METADATA_COLUMNS\n",
    "\n",
    "    # Prepare splits\n",
    "    old_ids = df_old_ids['id'].unique()\n",
    "    data_splits = {\n",
    "        \"All Data\": df_main,\n",
    "        \"Old Data\": df_main[df_main['id'].isin(old_ids)],\n",
    "        \"New Data\": df_main[~df_main['id'].isin(old_ids)]\n",
    "    }\n",
    "\n",
    "    # --- 2. Model Training ---\n",
    "    print(f\"Step 2: Training Random Forest models on '{target_variable}'...\")\n",
    "    models = {}\n",
    "    for name, data in data_splits.items():\n",
    "        print(f\"  - Training on '{name}' ({len(data)} rows)...\")\n",
    "\n",
    "        if target_variable not in data.columns:\n",
    "            print(f\"    ⚠️ Skipping '{name}' – target '{target_variable}' not in columns.\")\n",
    "            continue\n",
    "\n",
    "        # Drop rows missing the CURRENT target variable\n",
    "        df_clean = data.dropna(subset=[target_variable]).copy()\n",
    "\n",
    "        # Build X (numeric only), drop constant/all-NaN cols\n",
    "        X = df_clean.drop(columns=COLS_TO_DROP_FROM_X, errors='ignore')\n",
    "        X = X.select_dtypes(include=[np.number])\n",
    "        if X.shape[1] == 0:\n",
    "            print(f\"    ⚠️ Skipping '{name}' – no numeric predictors after cleaning.\")\n",
    "            continue\n",
    "        # drop all-NaN columns\n",
    "        X = X.loc[:, X.notna().any(axis=0)]\n",
    "        # drop constant columns\n",
    "        constant_cols = [c for c in X.columns if X[c].nunique(dropna=True) <= 1]\n",
    "        if constant_cols:\n",
    "            X = X.drop(columns=constant_cols)\n",
    "\n",
    "        y = df_clean[target_variable].astype(float)\n",
    "\n",
    "        n = len(y)\n",
    "        if n < 2:\n",
    "            print(f\"    ⚠️ Skipping '{name}' – insufficient samples after dropna (n={n}).\")\n",
    "            continue\n",
    "\n",
    "        # Enable OOB only when there are enough samples to make it meaningful\n",
    "        use_oob = n > 10\n",
    "        rf = RandomForestRegressor(\n",
    "            n_estimators=500,\n",
    "            random_state=42,\n",
    "            n_jobs=-1,\n",
    "            oob_score=use_oob\n",
    "        )\n",
    "        rf.fit(X, y)\n",
    "        if use_oob:\n",
    "            print(f\"    ...Done. Model OOB Score (R²): {rf.oob_score_:.3f}\")\n",
    "        else:\n",
    "            print(f\"    ...Done. (OOB disabled; n={n})\")\n",
    "\n",
    "        models[name] = {'model': rf, 'X': X}\n",
    "\n",
    "    if \"All Data\" not in models:\n",
    "        print(\"❌ No trainable 'All Data' model. Aborting PDP stage.\")\n",
    "        return\n",
    "\n",
    "    # --- 3. Generate and Save Partial Dependence Plots ---\n",
    "    feature_list = models['All Data']['X'].columns\n",
    "    print(f\"\\nStep 3: Generating {len(feature_list)} Partial Dependence Plots...\")\n",
    "\n",
    "    # Only include splits that successfully trained\n",
    "    trained_order = [k for k in [\"All Data\", \"Old Data\", \"New Data\"] if k in models]\n",
    "    if not trained_order:\n",
    "        print(\"❌ No trained models available for PDP.\")\n",
    "        return\n",
    "\n",
    "    for feature in feature_list:\n",
    "        print(f\"  - Plotting for: {feature}\")\n",
    "        fig, axes = plt.subplots(len(trained_order), 1, figsize=(8, 4 * len(trained_order)), sharex=True)\n",
    "        if len(trained_order) == 1:\n",
    "            axes = [axes]\n",
    "        fig.suptitle(f'Partial Dependence on: {feature}\\n(Target: {target_variable})', fontsize=16, y=0.96)\n",
    "\n",
    "        for ax, model_name in zip(axes, trained_order):\n",
    "            model_info = models[model_name]\n",
    "            try:\n",
    "                PartialDependenceDisplay.from_estimator(\n",
    "                    estimator=model_info['model'], X=model_info['X'], features=[feature],\n",
    "                    ax=ax, line_kw={\"color\": \"darkcyan\", \"linewidth\": 2.5}\n",
    "                )\n",
    "                ax.set_title(f\"{model_name} (n={len(model_info['X'])})\")\n",
    "                ax.set_ylabel(\"Partial Dependence\")\n",
    "                ax.grid(True, linestyle='--', alpha=0.6)\n",
    "            except Exception as e:\n",
    "                ax.set_title(f\"{model_name} – PDP failed for '{feature}' ({e})\")\n",
    "                ax.axis('off')\n",
    "\n",
    "        save_path = os.path.join(output_directory, f'{feature}.png')\n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.94])\n",
    "        plt.savefig(save_path)\n",
    "        plt.close(fig)\n",
    "\n",
    "    print(f\"\\n✅ ANALYSIS COMPLETE for '{target_variable}'. Plots saved to: {output_directory}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # --- Master Configuration ---\n",
    "    INPUT_CSV = \"/explore/nobackup/people/spotter5/new_combustion/2025-08-13_LC_FISL_Original_combustionModelPredictors.csv\"\n",
    "    OLD_PREDICTORS_CSV = \"/explore/nobackup/people/spotter5/new_combustion/Combustion_SynthesisData_05042018_XJW.csv\"\n",
    "    BASE_OUT_PATH = \"/explore/nobackup/people/spotter5/new_combustion\"\n",
    "\n",
    "    analyses = {\n",
    "        'below.ground.carbon.combusted': os.path.join(BASE_OUT_PATH, \"pdp_belowground\"),\n",
    "        'above.carbon.combusted': os.path.join(BASE_OUT_PATH, \"pdp_aboveground\"),\n",
    "        'burn.depth': os.path.join(BASE_OUT_PATH, \"pdp_depth\")\n",
    "    }\n",
    "\n",
    "    for target_col, out_dir in analyses.items():\n",
    "        run_pdp_analysis(\n",
    "            target_variable=target_col,\n",
    "            output_directory=out_dir,\n",
    "            input_csv_path=INPUT_CSV,\n",
    "            old_ids_csv_path=OLD_PREDICTORS_CSV\n",
    "        )\n",
    "\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"🎉 All tasks finished.\")\n",
    "    print(f\"{'='*70}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ceaa4973-6195-4a06-80bc-546c2f433216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "🚀 STARTING ANALYSIS | TARGET: 'below.ground.carbon.combusted'\n",
      "======================================================================\n",
      "Step 1: Loading and preparing data...\n",
      "Step 2: Training Random Forest models on 'below.ground.carbon.combusted'...\n",
      "  - Preparing data for 'All Data' (1877 rows)...\n",
      "    ... Cleaned predictor NaNs. Dropped 562 rows. Final training size: 1201\n",
      "    ... Done. Model OOB Score (R²): 0.358\n",
      "  - Preparing data for 'Old Data' (1011 rows)...\n",
      "    ... Cleaned predictor NaNs. Dropped 127 rows. Final training size: 770\n",
      "    ... Done. Model OOB Score (R²): 0.218\n",
      "  - Preparing data for 'New Data' (866 rows)...\n",
      "    ... Cleaned predictor NaNs. Dropped 435 rows. Final training size: 431\n",
      "    ... Done. Model OOB Score (R²): 0.559\n",
      "\n",
      "Step 3: Generating 73 Partial Dependence Plots...\n",
      "  - Plotting for: PFI\n",
      "  - Plotting for: pH_30\n",
      "  - Plotting for: Sand_30\n",
      "  - Plotting for: Silt_30\n",
      "  - Plotting for: Clay_30\n",
      "  - Plotting for: DOB_lst\n",
      "  - Plotting for: Relative.humidity\n",
      "  - Plotting for: Temperature\n",
      "  - Plotting for: VPD\n",
      "  - Plotting for: Wind.speed\n",
      "  - Plotting for: JP\n",
      "  - Plotting for: BS\n",
      "  - Plotting for: DEC\n",
      "  - Plotting for: GRSH\n",
      "  - Plotting for: NV\n",
      "  - Plotting for: OCON\n",
      "  - Plotting for: WS\n",
      "  - Plotting for: CNA_Tmax_5_8\n",
      "  - Plotting for: CNA_PPT_5_8\n",
      "  - Plotting for: CNA_Rad_5_8\n",
      "  - Plotting for: CNA_DD_0_5_8\n",
      "  - Plotting for: CNA_DD5_5_8\n",
      "  - Plotting for: CNA_DD_18_5_8\n",
      "  - Plotting for: CNA_DD18_sm\n",
      "  - Plotting for: CNA_NFFD_5_8\n",
      "  - Plotting for: CNA_PAS_5_8\n",
      "  - Plotting for: CNA_Eref_5_8\n",
      "  - Plotting for: CNA_CMD_5_8\n",
      "  - Plotting for: CNA_RH_5_8\n",
      "  - Plotting for: CNA_Tave_5_8\n",
      "  - Plotting for: CNA_Tmin_5_8\n",
      "  - Plotting for: CNA_MAT\n",
      "  - Plotting for: CNA_MWMT\n",
      "  - Plotting for: CNA_MCMT\n",
      "  - Plotting for: CNA_TD\n",
      "  - Plotting for: CNA_MAP\n",
      "  - Plotting for: CNA_MSP\n",
      "  - Plotting for: CNA_AHM\n",
      "  - Plotting for: CNA_SHM\n",
      "  - Plotting for: CNA_DD_0\n",
      "  - Plotting for: CNA_DD5\n",
      "  - Plotting for: CNA_DD_18\n",
      "  - Plotting for: CNA_DD18\n",
      "  - Plotting for: CNA_NFFD\n",
      "  - Plotting for: CNA_bFFP\n",
      "  - Plotting for: CNA_eFFP\n",
      "  - Plotting for: CNA_FFP\n",
      "  - Plotting for: CNA_PAS\n",
      "  - Plotting for: CNA_EMT\n",
      "  - Plotting for: CNA_EXT\n",
      "  - Plotting for: CNA_Eref\n",
      "  - Plotting for: CNA_CMD\n",
      "  - Plotting for: CNA_RH\n",
      "  - Plotting for: BD_30\n",
      "  - Plotting for: NDII\n",
      "  - Plotting for: NDVI\n",
      "  - Plotting for: SOC_30\n",
      "  - Plotting for: brightness\n",
      "  - Plotting for: dNBR\n",
      "  - Plotting for: greenness\n",
      "  - Plotting for: rbr\n",
      "  - Plotting for: Tree.cover\n",
      "  - Plotting for: wetness\n",
      "  - Plotting for: rdnbr\n",
      "  - Plotting for: BUI\n",
      "  - Plotting for: DC\n",
      "  - Plotting for: DMC\n",
      "  - Plotting for: FFMC\n",
      "  - Plotting for: FWI\n",
      "  - Plotting for: ISI\n",
      "  - Plotting for: DSR\n",
      "  - Plotting for: twi\n",
      "  - Plotting for: slope_rad\n",
      "\n",
      "✅ ANALYSIS COMPLETE for 'below.ground.carbon.combusted'. Plots saved to: /explore/nobackup/people/spotter5/new_combustion/pdp_belowground\n",
      "\n",
      "======================================================================\n",
      "🚀 STARTING ANALYSIS | TARGET: 'above.carbon.combusted'\n",
      "======================================================================\n",
      "Step 1: Loading and preparing data...\n",
      "Step 2: Training Random Forest models on 'above.carbon.combusted'...\n",
      "  - Preparing data for 'All Data' (1877 rows)...\n",
      "    ... Cleaned predictor NaNs. Dropped 501 rows. Final training size: 980\n",
      "    ... Done. Model OOB Score (R²): 0.355\n",
      "  - Preparing data for 'Old Data' (1011 rows)...\n",
      "    ... Cleaned predictor NaNs. Dropped 66 rows. Final training size: 549\n",
      "    ... Done. Model OOB Score (R²): 0.341\n",
      "  - Preparing data for 'New Data' (866 rows)...\n",
      "    ... Cleaned predictor NaNs. Dropped 435 rows. Final training size: 431\n",
      "    ... Done. Model OOB Score (R²): 0.330\n",
      "\n",
      "Step 3: Generating 73 Partial Dependence Plots...\n",
      "  - Plotting for: PFI\n",
      "  - Plotting for: pH_30\n",
      "  - Plotting for: Sand_30\n",
      "  - Plotting for: Silt_30\n",
      "  - Plotting for: Clay_30\n",
      "  - Plotting for: DOB_lst\n",
      "  - Plotting for: Relative.humidity\n",
      "  - Plotting for: Temperature\n",
      "  - Plotting for: VPD\n",
      "  - Plotting for: Wind.speed\n",
      "  - Plotting for: JP\n",
      "  - Plotting for: BS\n",
      "  - Plotting for: DEC\n",
      "  - Plotting for: GRSH\n",
      "  - Plotting for: NV\n",
      "  - Plotting for: OCON\n",
      "  - Plotting for: WS\n",
      "  - Plotting for: CNA_Tmax_5_8\n",
      "  - Plotting for: CNA_PPT_5_8\n",
      "  - Plotting for: CNA_Rad_5_8\n",
      "  - Plotting for: CNA_DD_0_5_8\n",
      "  - Plotting for: CNA_DD5_5_8\n",
      "  - Plotting for: CNA_DD_18_5_8\n",
      "  - Plotting for: CNA_DD18_sm\n",
      "  - Plotting for: CNA_NFFD_5_8\n",
      "  - Plotting for: CNA_PAS_5_8\n",
      "  - Plotting for: CNA_Eref_5_8\n",
      "  - Plotting for: CNA_CMD_5_8\n",
      "  - Plotting for: CNA_RH_5_8\n",
      "  - Plotting for: CNA_Tave_5_8\n",
      "  - Plotting for: CNA_Tmin_5_8\n",
      "  - Plotting for: CNA_MAT\n",
      "  - Plotting for: CNA_MWMT\n",
      "  - Plotting for: CNA_MCMT\n",
      "  - Plotting for: CNA_TD\n",
      "  - Plotting for: CNA_MAP\n",
      "  - Plotting for: CNA_MSP\n",
      "  - Plotting for: CNA_AHM\n",
      "  - Plotting for: CNA_SHM\n",
      "  - Plotting for: CNA_DD_0\n",
      "  - Plotting for: CNA_DD5\n",
      "  - Plotting for: CNA_DD_18\n",
      "  - Plotting for: CNA_DD18\n",
      "  - Plotting for: CNA_NFFD\n",
      "  - Plotting for: CNA_bFFP\n",
      "  - Plotting for: CNA_eFFP\n",
      "  - Plotting for: CNA_FFP\n",
      "  - Plotting for: CNA_PAS\n",
      "  - Plotting for: CNA_EMT\n",
      "  - Plotting for: CNA_EXT\n",
      "  - Plotting for: CNA_Eref\n",
      "  - Plotting for: CNA_CMD\n",
      "  - Plotting for: CNA_RH\n",
      "  - Plotting for: BD_30\n",
      "  - Plotting for: NDII\n",
      "  - Plotting for: NDVI\n",
      "  - Plotting for: SOC_30\n",
      "  - Plotting for: brightness\n",
      "  - Plotting for: dNBR\n",
      "  - Plotting for: greenness\n",
      "  - Plotting for: rbr\n",
      "  - Plotting for: Tree.cover\n",
      "  - Plotting for: wetness\n",
      "  - Plotting for: rdnbr\n",
      "  - Plotting for: BUI\n",
      "  - Plotting for: DC\n",
      "  - Plotting for: DMC\n",
      "  - Plotting for: FFMC\n",
      "  - Plotting for: FWI\n",
      "  - Plotting for: ISI\n",
      "  - Plotting for: DSR\n",
      "  - Plotting for: twi\n",
      "  - Plotting for: slope_rad\n",
      "\n",
      "✅ ANALYSIS COMPLETE for 'above.carbon.combusted'. Plots saved to: /explore/nobackup/people/spotter5/new_combustion/pdp_aboveground\n",
      "\n",
      "======================================================================\n",
      "🎉 All tasks finished.\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "def run_pdp_analysis(target_variable, output_directory, input_csv_path, old_ids_csv_path):\n",
    "    \"\"\"\n",
    "    Runs the full modeling and PDP generation pipeline for a specific target variable.\n",
    "\n",
    "    Args:\n",
    "        target_variable (str): The name of the column to use as the target.\n",
    "        output_directory (str): The path to save the generated PDP images.\n",
    "        input_csv_path (str): Path to the main input CSV file.\n",
    "        old_ids_csv_path (str): Path to the CSV containing old plot IDs.\n",
    "    \"\"\"\n",
    "    # --- Setup & Introduction ---\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"🚀 STARTING ANALYSIS | TARGET: '{target_variable}'\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "    warnings.filterwarnings('ignore', category=UserWarning)\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "    # --- 1. Data Preparation ---\n",
    "    print(\"Step 1: Loading and preparing data...\")\n",
    "    try:\n",
    "        df_main = pd.read_csv(input_csv_path)\n",
    "        df_old_ids = pd.read_csv(old_ids_csv_path)\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"❌ Error: Could not find input file. {e}\")\n",
    "        return\n",
    "\n",
    "    # Define columns to exclude from predictors.\n",
    "    POTENTIAL_TARGETS = ['below.ground.carbon.combusted', 'above.carbon.combusted']\n",
    "    METADATA_COLUMNS = [\n",
    "        'burn_year', 'project.name', 'latitude', 'longitude', 'Date', 'id',\n",
    "        'CNA_MAR', 'fireYr', 'lat', 'lon', 'project_name'\n",
    "    ]\n",
    "    \n",
    "    # Combine all columns to be dropped when creating the predictor set (X)\n",
    "    COLS_TO_DROP_FROM_X = POTENTIAL_TARGETS + METADATA_COLUMNS\n",
    "\n",
    "    # Prepare the three datasets (All, Old, New)\n",
    "    old_ids = df_old_ids['id'].unique()\n",
    "    data_splits = {\n",
    "        \"All Data\": df_main,\n",
    "        \"Old Data\": df_main[df_main['id'].isin(old_ids)],\n",
    "        \"New Data\": df_main[~df_main['id'].isin(old_ids)]\n",
    "    }\n",
    "\n",
    "    # --- 2. Model Training ---\n",
    "    print(f\"Step 2: Training Random Forest models on '{target_variable}'...\")\n",
    "    models = {}\n",
    "    for name, data in data_splits.items():\n",
    "        print(f\"  - Preparing data for '{name}' ({len(data)} rows)...\")\n",
    "\n",
    "        # First, drop rows where the CURRENT target variable is missing\n",
    "        df_clean_target = data.dropna(subset=[target_variable])\n",
    "\n",
    "        # Define predictors (X) and target (y) from this pre-cleaned data\n",
    "        X = df_clean_target.drop(columns=COLS_TO_DROP_FROM_X, errors='ignore')\n",
    "        y = df_clean_target[target_variable]\n",
    "\n",
    "        # --- START: FIX ---\n",
    "        # **CRITICAL FIX**: Now, drop rows with NaNs in the PREDICTOR (X) columns\n",
    "        # This ensures the model receives completely clean data.\n",
    "        rows_before_cleaning_predictors = len(X)\n",
    "        X = X.dropna()\n",
    "        \n",
    "        # **CRITICAL FIX**: Re-align y to match the cleaned X's index\n",
    "        y = y.loc[X.index]\n",
    "        rows_after_cleaning_predictors = len(X)\n",
    "        \n",
    "        if rows_before_cleaning_predictors > rows_after_cleaning_predictors:\n",
    "            rows_dropped = rows_before_cleaning_predictors - rows_after_cleaning_predictors\n",
    "            print(f\"    ... Cleaned predictor NaNs. Dropped {rows_dropped} rows. Final training size: {rows_after_cleaning_predictors}\")\n",
    "        # --- END: FIX ---\n",
    "\n",
    "        # Check if there is still data to train on\n",
    "        if X.empty:\n",
    "            print(f\"    ... ❌ Skipping '{name}': No data left after cleaning.\")\n",
    "            models[name] = None # Store None to indicate a failed model\n",
    "            continue\n",
    "\n",
    "        # Initialize and train the model\n",
    "        rf = RandomForestRegressor(n_estimators=500, random_state=42, n_jobs=-1, oob_score=True)\n",
    "        rf.fit(X, y)\n",
    "        print(f\"    ... Done. Model OOB Score (R²): {rf.oob_score_:.3f}\")\n",
    "\n",
    "        # Store the trained model and predictor data\n",
    "        models[name] = {'model': rf, 'X': X}\n",
    "\n",
    "    # --- 3. Generate and Save Partial Dependence Plots ---\n",
    "    # Use the 'All Data' model's features as the reference list\n",
    "    if models['All Data'] is None:\n",
    "        print(\"\\n❌ Cannot generate plots because 'All Data' model failed to train.\")\n",
    "        return\n",
    "        \n",
    "    feature_list = models['All Data']['X'].columns\n",
    "    print(f\"\\nStep 3: Generating {len(feature_list)} Partial Dependence Plots...\")\n",
    "\n",
    "    for feature in feature_list:\n",
    "        print(f\"  - Plotting for: {feature}\")\n",
    "        fig, axes = plt.subplots(3, 1, figsize=(8, 12), sharex=True, squeeze=False) # squeeze=False ensures axes is always 2D\n",
    "        axes = axes.flatten() # Flatten to a 1D array for easy iteration\n",
    "        fig.suptitle(f'Partial Dependence on: {feature}\\n(Target: {target_variable})', fontsize=16, y=0.96)\n",
    "\n",
    "        plot_order = [\"All Data\", \"Old Data\", \"New Data\"]\n",
    "        for i, model_name in enumerate(plot_order):\n",
    "            ax = axes[i]\n",
    "            model_info = models.get(model_name) # Use .get() for safety\n",
    "\n",
    "            if model_info:\n",
    "                PartialDependenceDisplay.from_estimator(\n",
    "                    estimator=model_info['model'], X=model_info['X'], features=[feature],\n",
    "                    ax=ax, line_kw={\"color\": \"darkcyan\", \"linewidth\": 2.5}\n",
    "                )\n",
    "                ax.set_title(f\"{model_name} (n={len(model_info['X'])})\")\n",
    "            else:\n",
    "                ax.text(0.5, 0.5, 'Model could not be trained\\n(No data available)', \n",
    "                        ha='center', va='center', transform=ax.transAxes, fontsize=12, color='red')\n",
    "                ax.set_title(f\"{model_name} (n=0)\")\n",
    "\n",
    "            ax.set_ylabel(\"Partial Dependence\")\n",
    "            ax.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "        save_path = os.path.join(output_directory, f'{feature}.png')\n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.94])\n",
    "        plt.savefig(save_path)\n",
    "        plt.close(fig)\n",
    "\n",
    "    print(f\"\\n✅ ANALYSIS COMPLETE for '{target_variable}'. Plots saved to: {output_directory}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # --- Master Configuration ---\n",
    "    INPUT_CSV = \"/explore/nobackup/people/spotter5/new_combustion/2025-08-08_LC_FISL_Original_combustionModelPredictors.csv\"\n",
    "    OLD_PREDICTORS_CSV = \"/explore/nobackup/people/spotter5/new_combustion/all_predictors.csv\"\n",
    "    BASE_OUT_PATH = \"/explore/nobackup/people/spotter5/new_combustion\"\n",
    "\n",
    "    # Define the analyses to run\n",
    "    analyses = {\n",
    "        'below.ground.carbon.combusted': os.path.join(BASE_OUT_PATH, \"pdp_belowground\"),\n",
    "        'above.carbon.combusted': os.path.join(BASE_OUT_PATH, \"pdp_aboveground\")\n",
    "    }\n",
    "\n",
    "    # Execute each analysis\n",
    "    for target_col, out_dir in analyses.items():\n",
    "        run_pdp_analysis(\n",
    "            target_variable=target_col,\n",
    "            output_directory=out_dir,\n",
    "            input_csv_path=INPUT_CSV,\n",
    "            old_ids_csv_path=OLD_PREDICTORS_CSV\n",
    "        )\n",
    "\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"🎉 All tasks finished.\")\n",
    "    print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e2b902e-b167-46da-86b6-c1f7ff1c844a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "🚀 STARTING COMBINED PDP ANALYSIS\n",
      "======================================================================\n",
      "Step 1: Loading and preparing data...\n",
      "\n",
      "Step 2: Training all Random Forest models...\n",
      "  Training models for target: 'above.carbon.combusted'\n",
      "    - Training on 'All Data' (1877 rows)...\n",
      "      ... Done. Model OOB Score (R²): 0.355\n",
      "    - Training on 'Old Data' (1011 rows)...\n",
      "      ... Done. Model OOB Score (R²): 0.341\n",
      "    - Training on 'New Data' (866 rows)...\n",
      "      ... Done. Model OOB Score (R²): 0.330\n",
      "  Training models for target: 'below.ground.carbon.combusted'\n",
      "    - Training on 'All Data' (1877 rows)...\n",
      "      ... Done. Model OOB Score (R²): 0.358\n",
      "    - Training on 'Old Data' (1011 rows)...\n",
      "      ... Done. Model OOB Score (R²): 0.218\n",
      "    - Training on 'New Data' (866 rows)...\n",
      "      ... Done. Model OOB Score (R²): 0.559\n",
      "\n",
      "Step 3: Generating 73 combined 3x2 Partial Dependence Plots...\n",
      "  - Plotting for: PFI\n",
      "  - Plotting for: pH_30\n",
      "  - Plotting for: Sand_30\n",
      "  - Plotting for: Silt_30\n",
      "  - Plotting for: Clay_30\n",
      "  - Plotting for: DOB_lst\n",
      "  - Plotting for: Relative.humidity\n",
      "  - Plotting for: Temperature\n",
      "  - Plotting for: VPD\n",
      "  - Plotting for: Wind.speed\n",
      "  - Plotting for: JP\n",
      "  - Plotting for: BS\n",
      "  - Plotting for: DEC\n",
      "  - Plotting for: GRSH\n",
      "  - Plotting for: NV\n",
      "  - Plotting for: OCON\n",
      "  - Plotting for: WS\n",
      "  - Plotting for: CNA_Tmax_5_8\n",
      "  - Plotting for: CNA_PPT_5_8\n",
      "  - Plotting for: CNA_Rad_5_8\n",
      "  - Plotting for: CNA_DD_0_5_8\n",
      "  - Plotting for: CNA_DD5_5_8\n",
      "  - Plotting for: CNA_DD_18_5_8\n",
      "  - Plotting for: CNA_DD18_sm\n",
      "  - Plotting for: CNA_NFFD_5_8\n",
      "  - Plotting for: CNA_PAS_5_8\n",
      "  - Plotting for: CNA_Eref_5_8\n",
      "  - Plotting for: CNA_CMD_5_8\n",
      "  - Plotting for: CNA_RH_5_8\n",
      "  - Plotting for: CNA_Tave_5_8\n",
      "  - Plotting for: CNA_Tmin_5_8\n",
      "  - Plotting for: CNA_MAT\n",
      "  - Plotting for: CNA_MWMT\n",
      "  - Plotting for: CNA_MCMT\n",
      "  - Plotting for: CNA_TD\n",
      "  - Plotting for: CNA_MAP\n",
      "  - Plotting for: CNA_MSP\n",
      "  - Plotting for: CNA_AHM\n",
      "  - Plotting for: CNA_SHM\n",
      "  - Plotting for: CNA_DD_0\n",
      "  - Plotting for: CNA_DD5\n",
      "  - Plotting for: CNA_DD_18\n",
      "  - Plotting for: CNA_DD18\n",
      "  - Plotting for: CNA_NFFD\n",
      "  - Plotting for: CNA_bFFP\n",
      "  - Plotting for: CNA_eFFP\n",
      "  - Plotting for: CNA_FFP\n",
      "  - Plotting for: CNA_PAS\n",
      "  - Plotting for: CNA_EMT\n",
      "  - Plotting for: CNA_EXT\n",
      "  - Plotting for: CNA_Eref\n",
      "  - Plotting for: CNA_CMD\n",
      "  - Plotting for: CNA_RH\n",
      "  - Plotting for: BD_30\n",
      "  - Plotting for: NDII\n",
      "  - Plotting for: NDVI\n",
      "  - Plotting for: SOC_30\n",
      "  - Plotting for: brightness\n",
      "  - Plotting for: dNBR\n",
      "  - Plotting for: greenness\n",
      "  - Plotting for: rbr\n",
      "  - Plotting for: Tree.cover\n",
      "  - Plotting for: wetness\n",
      "  - Plotting for: rdnbr\n",
      "  - Plotting for: BUI\n",
      "  - Plotting for: DC\n",
      "  - Plotting for: DMC\n",
      "  - Plotting for: FFMC\n",
      "  - Plotting for: FWI\n",
      "  - Plotting for: ISI\n",
      "  - Plotting for: DSR\n",
      "  - Plotting for: twi\n",
      "  - Plotting for: slope_rad\n",
      "\n",
      "======================================================================\n",
      "🎉 All tasks finished. Plots saved to: /explore/nobackup/people/spotter5/new_combustion/pdp_combined_3x2\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# --- 1. Setup & Configuration ---\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"🚀 STARTING COMBINED PDP ANALYSIS\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "# --- Master Configuration ---\n",
    "INPUT_CSV = \"/explore/nobackup/people/spotter5/new_combustion/2025-08-08_LC_FISL_Original_combustionModelPredictors.csv\"\n",
    "OLD_PREDICTORS_CSV = \"/explore/nobackup/people/spotter5/new_combustion/all_predictors.csv\"\n",
    "BASE_OUT_PATH = \"/explore/nobackup/people/spotter5/new_combustion\"\n",
    "COMBINED_OUTPUT_DIR = os.path.join(BASE_OUT_PATH, \"pdp_combined_3x2\")\n",
    "\n",
    "os.makedirs(COMBINED_OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# --- 2. Data Preparation ---\n",
    "print(\"Step 1: Loading and preparing data...\")\n",
    "try:\n",
    "    df_main = pd.read_csv(INPUT_CSV)\n",
    "    df_old_ids = pd.read_csv(OLD_PREDICTORS_CSV)\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"❌ Error: Could not find input file. {e}\")\n",
    "    exit()\n",
    "\n",
    "# Define columns to exclude from predictors\n",
    "POTENTIAL_TARGETS = ['above.carbon.combusted', 'below.ground.carbon.combusted']\n",
    "METADATA_COLUMNS = [\n",
    "    'burn_year', 'project.name', 'latitude', 'longitude', 'Date', 'id',\n",
    "    'CNA_MAR', 'fireYr', 'lat', 'lon', 'project_name'\n",
    "]\n",
    "COLS_TO_DROP_FROM_X = POTENTIAL_TARGETS + METADATA_COLUMNS\n",
    "\n",
    "# Prepare the three datasets (All, Old, New)\n",
    "old_ids = df_old_ids['id'].unique()\n",
    "data_splits = {\n",
    "    \"All Data\": df_main,\n",
    "    \"Old Data\": df_main[df_main['id'].isin(old_ids)],\n",
    "    \"New Data\": df_main[~df_main['id'].isin(old_ids)]\n",
    "}\n",
    "\n",
    "# --- 3. Train All Models ---\n",
    "print(\"\\nStep 2: Training all Random Forest models...\")\n",
    "models = {target: {} for target in POTENTIAL_TARGETS} # Nested dictionary to hold all 6 models\n",
    "\n",
    "for target_variable in POTENTIAL_TARGETS:\n",
    "    print(f\"  Training models for target: '{target_variable}'\")\n",
    "    for name, data in data_splits.items():\n",
    "        print(f\"    - Training on '{name}' ({len(data)} rows)...\")\n",
    "        \n",
    "        # Clean data for the current model\n",
    "        df_clean = data.dropna(subset=[target_variable])\n",
    "        X = df_clean.drop(columns=COLS_TO_DROP_FROM_X, errors='ignore')\n",
    "        y = df_clean[target_variable]\n",
    "        \n",
    "        # Drop NaNs from predictors and align y\n",
    "        X = X.dropna()\n",
    "        y = y.loc[X.index]\n",
    "\n",
    "        if X.empty:\n",
    "            print(f\"      ... ❌ Skipping '{name}': No data left after cleaning.\")\n",
    "            models[target_variable][name] = None\n",
    "            continue\n",
    "            \n",
    "        rf = RandomForestRegressor(n_estimators=500, random_state=42, n_jobs=-1, oob_score=True)\n",
    "        rf.fit(X, y)\n",
    "        print(f\"      ... Done. Model OOB Score (R²): {rf.oob_score_:.3f}\")\n",
    "        \n",
    "        # Store the trained model and predictor data\n",
    "        models[target_variable][name] = {'model': rf, 'X': X}\n",
    "\n",
    "# --- 4. Generate and Save 3x2 Partial Dependence Plots ---\n",
    "# Use one consistent feature list from the 'All Data' model\n",
    "all_data_model_info = models['above.carbon.combusted'].get('All Data')\n",
    "if not all_data_model_info:\n",
    "    print(\"\\n❌ Cannot generate plots because the 'All Data' model for aboveground failed to train.\")\n",
    "    exit()\n",
    "\n",
    "feature_list = all_data_model_info['X'].columns\n",
    "print(f\"\\nStep 3: Generating {len(feature_list)} combined 3x2 Partial Dependence Plots...\")\n",
    "\n",
    "plot_order = [\"All Data\", \"New Data\", \"Old Data\"]\n",
    "target_left = 'above.carbon.combusted'\n",
    "target_right = 'below.ground.carbon.combusted'\n",
    "\n",
    "for feature in feature_list:\n",
    "    print(f\"  - Plotting for: {feature}\")\n",
    "    \n",
    "    fig, axes = plt.subplots(3, 2, figsize=(15, 18), sharex=True)\n",
    "    fig.suptitle(f'Partial Dependence on: {feature}', fontsize=20, y=0.98)\n",
    "\n",
    "    for i, model_name in enumerate(plot_order):\n",
    "        # --- Left Column: Aboveground ---\n",
    "        ax_left = axes[i, 0]\n",
    "        model_info_left = models[target_left].get(model_name)\n",
    "        \n",
    "        if model_info_left:\n",
    "            PartialDependenceDisplay.from_estimator(\n",
    "                estimator=model_info_left['model'], X=model_info_left['X'], features=[feature],\n",
    "                ax=ax_left, line_kw={\"color\": \"darkcyan\", \"linewidth\": 2.5}\n",
    "            )\n",
    "        else:\n",
    "            ax_left.text(0.5, 0.5, 'Model Not Trained', ha='center', va='center', color='red')\n",
    "        \n",
    "        ax_left.set_ylabel(f\"{model_name}\\nPartial Dependence\")\n",
    "        ax_left.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "        # --- Right Column: Belowground ---\n",
    "        ax_right = axes[i, 1]\n",
    "        model_info_right = models[target_right].get(model_name)\n",
    "        \n",
    "        if model_info_right:\n",
    "            PartialDependenceDisplay.from_estimator(\n",
    "                estimator=model_info_right['model'], X=model_info_right['X'], features=[feature],\n",
    "                ax=ax_right, line_kw={\"color\": \"saddlebrown\", \"linewidth\": 2.5}\n",
    "            )\n",
    "        else:\n",
    "            ax_right.text(0.5, 0.5, 'Model Not Trained', ha='center', va='center', color='red')\n",
    "\n",
    "        ax_right.set_ylabel(\"\")\n",
    "        ax_right.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "    # Set titles for the top row\n",
    "    axes[0, 0].set_title(\"Target: Aboveground Carbon\", fontsize=14)\n",
    "    axes[0, 1].set_title(\"Target: Belowground Carbon\", fontsize=14)\n",
    "    \n",
    "    # Set shared x-axis label for the bottom row\n",
    "    axes[2, 0].set_xlabel(feature)\n",
    "    axes[2, 1].set_xlabel(feature)\n",
    "\n",
    "    save_path = os.path.join(COMBINED_OUTPUT_DIR, f'{feature}_combined_pdp.png')\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plt.savefig(save_path, dpi=150)\n",
    "    plt.close(fig)\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"🎉 All tasks finished. Plots saved to: {COMBINED_OUTPUT_DIR}\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78f80fee-3d64-455b-a068-f7b630fee506",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'t'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d5db2d-5463-4a16-9369-1e367eef1a8c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-xgboost_gpu]",
   "language": "python",
   "name": "conda-env-.conda-xgboost_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
