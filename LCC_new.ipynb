{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae8c33a7-a6b7-4875-913a-ad444883d7e4",
   "metadata": {},
   "source": [
    "With tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2ad54a6-4297-4b34-a847-1b4d0d8b9714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading: /explore/nobackup/people/spotter5/new_combustion/2025-10-03_CombustionModelPredictors.csv\n",
      "\n",
      "Target: combusted_above | X: (270, 50) | y: (270,)\n",
      "\n",
      "[combusted_above] Starting global RandomizedSearchCV with 40 iterations...\n",
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "[combusted_above] Best params: {'bootstrap': True, 'max_depth': 19, 'max_features': 0.413424811420228, 'min_samples_leaf': 2, 'min_samples_split': 3, 'n_estimators': 419}\n",
      "[combusted_above] RandomizedSearch best CV RMSE: 402.8719 kgC/m2\n",
      "\n",
      "[combusted_above] Starting LOOCV with fixed best hyperparameters...\n",
      "  LOOCV progress: 25/270\n",
      "  LOOCV progress: 50/270\n",
      "  LOOCV progress: 75/270\n",
      "  LOOCV progress: 100/270\n",
      "  LOOCV progress: 125/270\n",
      "  LOOCV progress: 150/270\n",
      "  LOOCV progress: 175/270\n",
      "  LOOCV progress: 200/270\n",
      "  LOOCV progress: 225/270\n",
      "  LOOCV progress: 250/270\n",
      "  LOOCV progress: 270/270\n",
      "[combusted_above] LOOCV RMSE (global): 387.2333 | R² (global, clamped): 0.2224 (raw: 0.2224)\n",
      "[combusted_above] Saved per-fold R² CSV: /explore/nobackup/people/spotter5/new_combustion/LCC_new/combusted_above_violin.csv\n",
      "[combusted_above] Saved LOOCV predictions (with fold R²) to: /explore/nobackup/people/spotter5/new_combustion/LCC_new/combusted_above_loocv_predictions.csv\n",
      "[combusted_above] Saved violin plot of per-fold R²: /explore/nobackup/people/spotter5/new_combustion/LCC_new/combusted_above_violin.png\n",
      "[combusted_above] Saved feature importance CSV: /explore/nobackup/people/spotter5/new_combustion/LCC_new/combusted_above_feature_importance.csv\n",
      "[combusted_above] Saved feature importance plot: /explore/nobackup/people/spotter5/new_combustion/LCC_new/combusted_above_feature_importance.png\n",
      "[combusted_above] Final model trained with 50 features; 'combusted_above' in features? False\n",
      "\n",
      "Target: combusted_below | X: (270, 50) | y: (270,)\n",
      "\n",
      "[combusted_below] Starting global RandomizedSearchCV with 40 iterations...\n",
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "[combusted_below] Best params: {'bootstrap': True, 'max_depth': 19, 'max_features': 0.413424811420228, 'min_samples_leaf': 2, 'min_samples_split': 3, 'n_estimators': 419}\n",
      "[combusted_below] RandomizedSearch best CV RMSE: 1526.9169 kgC/m2\n",
      "\n",
      "[combusted_below] Starting LOOCV with fixed best hyperparameters...\n",
      "  LOOCV progress: 25/270\n",
      "  LOOCV progress: 50/270\n",
      "  LOOCV progress: 75/270\n",
      "  LOOCV progress: 100/270\n",
      "  LOOCV progress: 125/270\n",
      "  LOOCV progress: 150/270\n",
      "  LOOCV progress: 175/270\n",
      "  LOOCV progress: 200/270\n",
      "  LOOCV progress: 225/270\n",
      "  LOOCV progress: 250/270\n",
      "  LOOCV progress: 270/270\n",
      "[combusted_below] LOOCV RMSE (global): 1385.4286 | R² (global, clamped): 0.3146 (raw: 0.3146)\n",
      "[combusted_below] Saved per-fold R² CSV: /explore/nobackup/people/spotter5/new_combustion/LCC_new/combusted_below_violin.csv\n",
      "[combusted_below] Saved LOOCV predictions (with fold R²) to: /explore/nobackup/people/spotter5/new_combustion/LCC_new/combusted_below_loocv_predictions.csv\n",
      "[combusted_below] Saved violin plot of per-fold R²: /explore/nobackup/people/spotter5/new_combustion/LCC_new/combusted_below_violin.png\n",
      "[combusted_below] Saved feature importance CSV: /explore/nobackup/people/spotter5/new_combustion/LCC_new/combusted_below_feature_importance.csv\n",
      "[combusted_below] Saved feature importance plot: /explore/nobackup/people/spotter5/new_combustion/LCC_new/combusted_below_feature_importance.png\n",
      "[combusted_below] Final model trained with 50 features; 'combusted_below' in features? False\n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import LeaveOneOut, KFold, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score, make_scorer\n",
    "from scipy.stats import randint, uniform\n",
    "import joblib\n",
    "\n",
    "# ----------------- PATHS -----------------\n",
    "INPUT_CSV = \"/explore/nobackup/people/spotter5/new_combustion/2025-10-03_CombustionModelPredictors.csv\"\n",
    "OUT_DIR   = \"/explore/nobackup/people/spotter5/new_combustion/LCC_new\"\n",
    "MODEL_DIR = os.path.join(OUT_DIR, \"models\")\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "# ----------------- SEARCH CONFIG -----------------\n",
    "RANDOM_STATE   = 42\n",
    "N_JOBS         = -1\n",
    "INNER_FOLDS    = 5\n",
    "N_ITER_SEARCH  = 40\n",
    "SCORER         = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "\n",
    "RF_PARAM_DIST = {\n",
    "    \"n_estimators\": randint(200, 1000),\n",
    "    \"max_depth\":    randint(3, 40),\n",
    "    \"max_features\": uniform(0.2, 0.8),  # float in (0,1]: fraction of features\n",
    "    \"min_samples_split\": randint(2, 20),\n",
    "    \"min_samples_leaf\":  randint(1, 10),\n",
    "    \"bootstrap\":   [True, False]\n",
    "}\n",
    "\n",
    "print(f\"Reading: {INPUT_CSV}\")\n",
    "df = pd.read_csv(INPUT_CSV)\n",
    "df = df[df['project'] .isin (['FISL', 'LC'])]\n",
    "\n",
    "# ----------------- BASIC CLEANUP -----------------\n",
    "df.columns = [c.strip() for c in df.columns]\n",
    "rename_map = {}\n",
    "if 'ID' in df.columns: rename_map['ID'] = 'id'\n",
    "if 'Id' in df.columns: rename_map['Id'] = 'id'\n",
    "if 'project_name' in df.columns and 'project.name' not in df.columns:\n",
    "    rename_map['project_name'] = 'project.name'\n",
    "if 'Date' in df.columns and 'date' not in df.columns:\n",
    "    rename_map['Date'] = 'date'\n",
    "if 'latitude' in df.columns and 'lat' not in df.columns:\n",
    "    rename_map['latitude'] = 'lat'\n",
    "if 'longitude' in df.columns and 'lon' not in df.columns:\n",
    "    rename_map['longitude'] = 'lon'\n",
    "if 'fireYr' in df.columns and 'burn_year' not in df.columns:\n",
    "    rename_map['fireYr'] = 'burn_year'\n",
    "df = df.rename(columns=rename_map)\n",
    "\n",
    "# Schema snapshot\n",
    "schema = pd.DataFrame({\n",
    "    \"column\": df.columns,\n",
    "    \"dtype\": df.dtypes.astype(str),\n",
    "    \"n_null\": df.isna().sum(),\n",
    "    \"n_unique\": [df[c].nunique(dropna=True) for c in df.columns]\n",
    "})\n",
    "schema.to_csv(os.path.join(OUT_DIR, \"schema_summary.csv\"), index=False)\n",
    "\n",
    "# ----------------- CATEGORICAL: LandCover -> one-hot -----------------\n",
    "if 'LandCover' in df.columns:\n",
    "    df = pd.get_dummies(df, columns=['LandCover'], prefix='LC', drop_first=True, dummy_na=False)\n",
    "\n",
    "# ----------------- EXCLUDED PREDICTOR COLUMNS -----------------\n",
    "EXCLUDE_PRED_COLS = {\n",
    "    'id', 'project.name', 'lat', 'lon', 'burn_year', 'date', 'project',\n",
    "    'ID', 'Id', 'project_name', 'latitude', 'longitude', 'fireYr', 'Date',\n",
    "    'landcover_name'\n",
    "}\n",
    "\n",
    "# ----------------- TARGET PICKER -----------------\n",
    "def pick_col(candidates):\n",
    "    for c in candidates:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "# Try to detect column names for aboveground, belowground, and burn depth\n",
    "COL_ABOVE = pick_col(['combusted_above', 'above.carbon.combusted'])\n",
    "COL_BELOW = pick_col(['combusted_below'])\n",
    "COL_DEPTH = pick_col(['burn_depth'])\n",
    "\n",
    "# We will train ABOVEGROUND and BELOWGROUND combustion models now\n",
    "targets = []\n",
    "if COL_ABOVE:\n",
    "    targets.append((COL_ABOVE, \"kgC/m2\"))   # adjust units as desired\n",
    "if COL_BELOW:\n",
    "    targets.append((COL_BELOW, \"kgC/m2\"))   # adjust units as desired\n",
    "\n",
    "if not targets:\n",
    "    raise ValueError(\"None of the expected aboveground or belowground target columns were found in the dataset.\")\n",
    "\n",
    "# IMPORTANT: include ALL possible combustion-related targets so they can be dropped from predictors\n",
    "ALL_TARGET_COLS = [c for c in [COL_ABOVE, COL_BELOW, COL_DEPTH] if c]\n",
    "\n",
    "# ----------------- Helper: build X, y -----------------\n",
    "def build_xy(df_in: pd.DataFrame, target_col: str):\n",
    "    # Drop obvious non-predictor columns\n",
    "    drop_cols = [c for c in EXCLUDE_PRED_COLS if c in df_in.columns]\n",
    "    work = df_in.drop(columns=drop_cols, errors='ignore').copy()\n",
    "\n",
    "    # Keep only rows with non-NaN target\n",
    "    work = work.dropna(subset=[target_col])\n",
    "\n",
    "    y = work[target_col].astype(float).copy()\n",
    "\n",
    "    # Drop the explicit target AND any other known combustion targets (above, below, depth)\n",
    "    X = work.drop(columns=list(set(ALL_TARGET_COLS + [target_col])), errors='ignore')\n",
    "\n",
    "    # Guard against accidental leakage of any combustion target\n",
    "    leak_cols = [c for c in [COL_ABOVE, COL_BELOW, COL_DEPTH] if c]\n",
    "    for lc in leak_cols:\n",
    "        assert lc not in X.columns, f\"Target leakage: {lc} present in predictors!\"\n",
    "\n",
    "    non_numeric = X.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "    if non_numeric:\n",
    "        X = X.drop(columns=non_numeric)\n",
    "\n",
    "    # Sanity: no empty feature set\n",
    "    if X.shape[1] == 0:\n",
    "        raise ValueError(f\"No numeric predictors left after preprocessing for target '{target_col}'.\")\n",
    "    return X, y\n",
    "\n",
    "# ----------------- RandomizedSearch + LOOCV with per-fold R² -----------------\n",
    "def run_target_randomsearch_loocv(target_col: str, units_label: str = \"units\"):\n",
    "    X, y = build_xy(df, target_col)\n",
    "    if X.shape[1] == 0 or len(y) < 3:\n",
    "        print(f\"[ERROR] Not enough predictors or samples for '{target_col}'.\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\nTarget: {target_col} | X: {X.shape} | y: {y.shape}\")\n",
    "    y = y.reset_index(drop=True)\n",
    "    X = X.reset_index(drop=True)\n",
    "    out_prefix = target_col.replace('.', '_')\n",
    "\n",
    "    # 1. RandomizedSearchCV (global)\n",
    "    print(f\"\\n[{target_col}] Starting global RandomizedSearchCV with {N_ITER_SEARCH} iterations...\")\n",
    "    kfold = KFold(n_splits=min(INNER_FOLDS, len(y)), shuffle=True, random_state=RANDOM_STATE)\n",
    "    base = RandomForestRegressor(random_state=RANDOM_STATE, n_jobs=N_JOBS)\n",
    "    tuner = RandomizedSearchCV(\n",
    "        estimator=base,\n",
    "        param_distributions=RF_PARAM_DIST,\n",
    "        n_iter=N_ITER_SEARCH,\n",
    "        scoring=SCORER,\n",
    "        cv=kfold,\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=N_JOBS,\n",
    "        verbose=1,\n",
    "        refit=True,\n",
    "    )\n",
    "    tuner.fit(X, y)\n",
    "\n",
    "    # Leakage sanity check: the tuned model must NOT expect any combustion target as a feature\n",
    "    tuned_features = list(getattr(tuner.best_estimator_, \"feature_names_in_\", []))\n",
    "    leak_cols = [c for c in [COL_ABOVE, COL_BELOW, COL_DEPTH] if c]\n",
    "    for lc in leak_cols:\n",
    "        if lc in tuned_features:\n",
    "            raise RuntimeError(\n",
    "                f\"Leakage detected: tuned model expects combustion target '{lc}' as a feature. \"\n",
    "                f\"Check preprocessing.\"\n",
    "            )\n",
    "\n",
    "    best_params = tuner.best_params_\n",
    "    best_neg_mse = float(tuner.best_score_)\n",
    "    best_rmse = float(np.sqrt(-best_neg_mse))\n",
    "    print(f\"[{target_col}] Best params: {best_params}\")\n",
    "    print(f\"[{target_col}] RandomizedSearch best CV RMSE: {best_rmse:.4f} {units_label}\")\n",
    "    rs_results = pd.DataFrame(tuner.cv_results_)\n",
    "    rs_results.to_csv(os.path.join(OUT_DIR, f\"{out_prefix}_random_search_results.csv\"), index=False)\n",
    "\n",
    "    # 2. LOOCV using best params\n",
    "    print(f\"\\n[{target_col}] Starting LOOCV with fixed best hyperparameters...\")\n",
    "    loo = LeaveOneOut()\n",
    "    n = len(y)\n",
    "    y_pred = np.zeros(n, dtype=float)\n",
    "    r2_folds = np.full(n, np.nan, dtype=float)  # one R² per left-out observation\n",
    "    train_means = np.full(n, np.nan, dtype=float)\n",
    "\n",
    "    for i, (train_idx, test_idx) in enumerate(loo.split(X), start=1):\n",
    "        Xtr, Xte = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        ytr = y.iloc[train_idx]\n",
    "        yte = y.iloc[test_idx].values[0]\n",
    "\n",
    "        model = RandomForestRegressor(random_state=RANDOM_STATE, n_jobs=N_JOBS, **best_params)\n",
    "        model.fit(Xtr, ytr)\n",
    "        yhat = model.predict(Xte)[0]\n",
    "\n",
    "        # store prediction\n",
    "        test_i = test_idx[0]\n",
    "        y_pred[test_i] = yhat\n",
    "\n",
    "        # per-fold R² for this left-out sample\n",
    "        mu_train = float(ytr.mean())\n",
    "        train_means[test_i] = mu_train\n",
    "        denom = (yte - mu_train)**2\n",
    "        num = (yte - yhat)**2\n",
    "\n",
    "        # if denom == 0, R² is undefined -> keep NaN\n",
    "        if denom != 0.0:\n",
    "            r2_val = 1.0 - (num / denom)\n",
    "            # clamp negative R² to 0\n",
    "            if r2_val < 0.0:\n",
    "                r2_val = 0.0\n",
    "            r2_folds[test_i] = r2_val\n",
    "\n",
    "        if i % 25 == 0 or i == n:\n",
    "            print(f\"  LOOCV progress: {i}/{n}\")\n",
    "\n",
    "    # Global LOOCV metrics over all predictions\n",
    "    rmse_global = mean_squared_error(y, y_pred, squared=False)\n",
    "    r2_raw_global = r2_score(y, y_pred)\n",
    "    # clamp negative global R² to 0 as well\n",
    "    r2_global = max(0.0, r2_raw_global)\n",
    "    print(f\"[{target_col}] LOOCV RMSE (global): {rmse_global:.4f} | R² (global, clamped): {r2_global:.4f} (raw: {r2_raw_global:.4f})\")\n",
    "\n",
    "    # Save per-sample predictions + per-fold R²\n",
    "    preds_df = pd.DataFrame({\n",
    "        \"index\": np.arange(n),\n",
    "        \"y_obs\": y.values,\n",
    "        \"y_pred\": y_pred,\n",
    "        \"train_mean_y\": train_means,\n",
    "        \"r2_loocv_fold\": r2_folds\n",
    "    })\n",
    "\n",
    "    # CSV for violin plot\n",
    "    violin_csv_path = os.path.join(OUT_DIR, f\"{out_prefix}_violin.csv\")\n",
    "    preds_df.to_csv(violin_csv_path, index=False)\n",
    "    print(f\"[{target_col}] Saved per-fold R² CSV: {violin_csv_path}\")\n",
    "\n",
    "    # Also keep the LOOCV predictions CSV\n",
    "    preds_path = os.path.join(OUT_DIR, f\"{out_prefix}_loocv_predictions.csv\")\n",
    "    preds_df.to_csv(preds_path, index=False)\n",
    "    print(f\"[{target_col}] Saved LOOCV predictions (with fold R²) to: {preds_path}\")\n",
    "\n",
    "    # Save summary metrics\n",
    "    pd.DataFrame({\n",
    "        \"target\": [target_col],\n",
    "        \"n\": [n],\n",
    "        \"n_predictors\": [X.shape[1]],\n",
    "        \"loocv_rmse_global\": [rmse_global],\n",
    "        \"loocv_r2_global_clamped\": [r2_global],\n",
    "        \"loocv_r2_global_raw\": [r2_raw_global],\n",
    "        \"random_search_best_rmse\": [best_rmse]\n",
    "    }).to_csv(os.path.join(OUT_DIR, f\"{out_prefix}_loocv_metrics.csv\"), index=False)\n",
    "\n",
    "    # Plot 1:1 scatter (global)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.scatterplot(x=preds_df[\"y_obs\"], y=preds_df[\"y_pred\"], s=18, edgecolor=None)\n",
    "    lo = float(np.nanmin([preds_df[\"y_obs\"].min(), preds_df[\"y_pred\"].min()]))\n",
    "    hi = float(np.nanmax([preds_df[\"y_obs\"].max(), preds_df[\"y_pred\"].max()]))\n",
    "    plt.plot([lo, hi], [lo, hi], 'k--', lw=2)\n",
    "    plt.xlabel(f\"Observed {target_col}\")\n",
    "    plt.ylabel(f\"Predicted {target_col}\")\n",
    "    plt.title(f\"{target_col}: LOOCV Obs vs Pred\\nRMSE={rmse_global:.3f}, R²={r2_global:.3f} (clamped)\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUT_DIR, f\"{out_prefix}_loocv_obs_pred.png\"), dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "    # ----------------- VIOLIN PLOT OF PER-FOLD R² -----------------\n",
    "    valid_r2 = preds_df[\"r2_loocv_fold\"].dropna()\n",
    "    if len(valid_r2) > 0:\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        sns.violinplot(y=valid_r2, cut=0)\n",
    "        plt.ylabel(\"Per-fold LOOCV R²\")\n",
    "        plt.title(f\"Distribution of LOOCV R² per left-out sample\\nTarget: {target_col}\")\n",
    "        plt.grid(axis='y', alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        violin_png_path = os.path.join(OUT_DIR, f\"{out_prefix}_violin.png\")\n",
    "        plt.savefig(violin_png_path, dpi=150)\n",
    "        plt.close()\n",
    "        print(f\"[{target_col}] Saved violin plot of per-fold R²: {violin_png_path}\")\n",
    "    else:\n",
    "        print(f\"[{target_col}] No valid per-fold R² values (all denominators zero). Skipping violin plot.\")\n",
    "\n",
    "    # Save model + metadata (with feature names!)\n",
    "    final_model = RandomForestRegressor(random_state=RANDOM_STATE, n_jobs=N_JOBS, **best_params)\n",
    "    final_model.fit(X, y)\n",
    "    model_path = os.path.join(MODEL_DIR, f\"rf_final_{out_prefix}.joblib\")\n",
    "    joblib.dump(final_model, model_path)\n",
    "\n",
    "    feature_names = list(getattr(final_model, \"feature_names_in_\", X.columns))\n",
    "\n",
    "    # --------------- NEW: FEATURE IMPORTANCE CSV + PLOT ---------------\n",
    "    importances = final_model.feature_importances_\n",
    "    fi_df = pd.DataFrame({\n",
    "        \"feature\": feature_names,\n",
    "        \"importance\": importances\n",
    "    }).sort_values(\"importance\", ascending=False)\n",
    "\n",
    "    fi_csv_path = os.path.join(OUT_DIR, f\"{out_prefix}_feature_importance.csv\")\n",
    "    fi_df.to_csv(fi_csv_path, index=False)\n",
    "    print(f\"[{target_col}] Saved feature importance CSV: {fi_csv_path}\")\n",
    "\n",
    "    # Barplot of top N features\n",
    "    top_n = min(30, len(fi_df))\n",
    "    fi_top = fi_df.head(top_n)\n",
    "\n",
    "    plt.figure(figsize=(10, max(6, 0.3 * top_n)))\n",
    "    sns.barplot(data=fi_top, x=\"importance\", y=\"feature\", orient=\"h\")\n",
    "    plt.xlabel(\"Random Forest feature importance\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "    plt.title(f\"Feature importance (top {top_n})\\nTarget: {target_col}\")\n",
    "    plt.tight_layout()\n",
    "    fi_png_path = os.path.join(OUT_DIR, f\"{out_prefix}_feature_importance.png\")\n",
    "    plt.savefig(fi_png_path, dpi=150)\n",
    "    plt.close()\n",
    "    print(f\"[{target_col}] Saved feature importance plot: {fi_png_path}\")\n",
    "    # --------------- END NEW BLOCK -----------------\n",
    "\n",
    "    meta = {\n",
    "        \"target\": target_col,\n",
    "        \"loocv_rmse_global\": rmse_global,\n",
    "        \"loocv_r2_global_clamped\": r2_global,\n",
    "        \"loocv_r2_global_raw\": r2_raw_global,\n",
    "        \"best_params\": best_params,\n",
    "        \"model_path\": model_path,\n",
    "        \"n_samples\": n,\n",
    "        \"feature_names\": feature_names\n",
    "    }\n",
    "    with open(os.path.join(OUT_DIR, f\"{out_prefix}_final_model_metadata.json\"), \"w\") as f:\n",
    "        json.dump(meta, f, indent=2)\n",
    "\n",
    "    # Extra sanity message\n",
    "    print(f\"[{target_col}] Final model trained with {len(meta['feature_names'])} features; \"\n",
    "          f\"'{target_col}' in features? {target_col in meta['feature_names']}\")\n",
    "\n",
    "# ----------------- RUN FOR EACH TARGET (ABOVEGROUND, BELOWGROUND) -----------------\n",
    "for tcol, units in targets:\n",
    "    run_target_randomsearch_loocv(tcol, units)\n",
    "\n",
    "print(\"\\nDone.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4eb558d-2f2b-47cd-aa32-3188be6f2389",
   "metadata": {},
   "source": [
    "Just depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53f16273-aafb-4a5a-924a-0f72a741751b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading: /explore/nobackup/people/spotter5/new_combustion/2025-10-03_CombustionModelPredictors.csv\n",
      "\n",
      "Target: burn_depth | X: (270, 50) | y: (270,)\n",
      "\n",
      "[burn_depth] Starting global RandomizedSearchCV with 40 iterations...\n",
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "[burn_depth] Best params: {'bootstrap': True, 'max_depth': 14, 'max_features': 0.40142583666029136, 'min_samples_leaf': 2, 'min_samples_split': 4, 'n_estimators': 312}\n",
      "[burn_depth] RandomizedSearch best CV RMSE: 5.3291 units\n",
      "\n",
      "[burn_depth] Starting LOOCV with fixed best hyperparameters...\n",
      "  LOOCV progress: 25/270\n",
      "  LOOCV progress: 50/270\n",
      "  LOOCV progress: 75/270\n",
      "  LOOCV progress: 100/270\n",
      "  LOOCV progress: 125/270\n",
      "  LOOCV progress: 150/270\n",
      "  LOOCV progress: 175/270\n",
      "  LOOCV progress: 200/270\n",
      "  LOOCV progress: 225/270\n",
      "  LOOCV progress: 250/270\n",
      "  LOOCV progress: 270/270\n",
      "[burn_depth] LOOCV RMSE (global): 4.8438 | R² (global, clamped): 0.3910 (raw: 0.3910)\n",
      "[burn_depth] Saved per-fold R² CSV: /explore/nobackup/people/spotter5/new_combustion/LCC_new/burn_depth_violin.csv\n",
      "[burn_depth] Saved LOOCV predictions (with fold R²) to: /explore/nobackup/people/spotter5/new_combustion/LCC_new/burn_depth_loocv_predictions.csv\n",
      "[burn_depth] Saved violin plot of per-fold R²: /explore/nobackup/people/spotter5/new_combustion/LCC_new/burn_depth_violin.png\n",
      "[burn_depth] Saved feature importance CSV: /explore/nobackup/people/spotter5/new_combustion/LCC_new/burn_depth_feature_importance.csv\n",
      "[burn_depth] Saved feature importance plot: /explore/nobackup/people/spotter5/new_combustion/LCC_new/burn_depth_feature_importance.png\n",
      "[burn_depth] Final model trained with 50 features; 'burn_depth' in features? False\n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import LeaveOneOut, KFold, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score, make_scorer\n",
    "from scipy.stats import randint, uniform\n",
    "import joblib\n",
    "\n",
    "# ----------------- PATHS -----------------\n",
    "INPUT_CSV = \"/explore/nobackup/people/spotter5/new_combustion/2025-10-03_CombustionModelPredictors.csv\"\n",
    "OUT_DIR   = \"/explore/nobackup/people/spotter5/new_combustion/LCC_new\"\n",
    "MODEL_DIR = os.path.join(OUT_DIR, \"models\")\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "# ----------------- SEARCH CONFIG -----------------\n",
    "RANDOM_STATE   = 42\n",
    "N_JOBS         = -1\n",
    "INNER_FOLDS    = 5\n",
    "N_ITER_SEARCH  = 40\n",
    "SCORER         = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "\n",
    "RF_PARAM_DIST = {\n",
    "    \"n_estimators\": randint(200, 1000),\n",
    "    \"max_depth\":    randint(3, 40),\n",
    "    \"max_features\": uniform(0.2, 0.8),  # float in (0,1]: fraction of features\n",
    "    \"min_samples_split\": randint(2, 20),\n",
    "    \"min_samples_leaf\":  randint(1, 10),\n",
    "    \"bootstrap\":   [True, False]\n",
    "}\n",
    "\n",
    "print(f\"Reading: {INPUT_CSV}\")\n",
    "df = pd.read_csv(INPUT_CSV)\n",
    "df = df[df['project'] .isin (['FISL', 'LC'])]\n",
    "\n",
    "# ----------------- BASIC CLEANUP -----------------\n",
    "df.columns = [c.strip() for c in df.columns]\n",
    "rename_map = {}\n",
    "if 'ID' in df.columns: rename_map['ID'] = 'id'\n",
    "if 'Id' in df.columns: rename_map['Id'] = 'id'\n",
    "if 'project_name' in df.columns and 'project.name' not in df.columns:\n",
    "    rename_map['project_name'] = 'project.name'\n",
    "if 'Date' in df.columns and 'date' not in df.columns:\n",
    "    rename_map['Date'] = 'date'\n",
    "if 'latitude' in df.columns and 'lat' not in df.columns:\n",
    "    rename_map['latitude'] = 'lat'\n",
    "if 'longitude' in df.columns and 'lon' not in df.columns:\n",
    "    rename_map['longitude'] = 'lon'\n",
    "if 'fireYr' in df.columns and 'burn_year' not in df.columns:\n",
    "    rename_map['fireYr'] = 'burn_year'\n",
    "df = df.rename(columns=rename_map)\n",
    "\n",
    "# Schema snapshot\n",
    "schema = pd.DataFrame({\n",
    "    \"column\": df.columns,\n",
    "    \"dtype\": df.dtypes.astype(str),\n",
    "    \"n_null\": df.isna().sum(),\n",
    "    \"n_unique\": [df[c].nunique(dropna=True) for c in df.columns]\n",
    "})\n",
    "schema.to_csv(os.path.join(OUT_DIR, \"schema_summary.csv\"), index=False)\n",
    "\n",
    "# ----------------- CATEGORICAL: LandCover -> one-hot -----------------\n",
    "if 'LandCover' in df.columns:\n",
    "    df = pd.get_dummies(df, columns=['LandCover'], prefix='LC', drop_first=True, dummy_na=False)\n",
    "\n",
    "# ----------------- EXCLUDED PREDICTOR COLUMNS -----------------\n",
    "EXCLUDE_PRED_COLS = {\n",
    "    'id', 'project.name', 'lat', 'lon', 'burn_year', 'date', 'project',\n",
    "    'ID', 'Id', 'project_name', 'latitude', 'longitude', 'fireYr', 'Date',\n",
    "    'landcover_name'\n",
    "}\n",
    "\n",
    "# ----------------- TARGET PICKER -----------------\n",
    "def pick_col(candidates):\n",
    "    for c in candidates:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "COL_ABOVE = pick_col(['combusted_above', 'above.carbon.combusted'])\n",
    "COL_BELOW = pick_col(['combusted_below'])\n",
    "COL_DEPTH = pick_col(['burn_depth'])\n",
    "\n",
    "# >>> Train burn_depth only for now <<<\n",
    "targets = [(c, \"units\") for c in [COL_DEPTH] if c]\n",
    "if not targets:\n",
    "    raise ValueError(\"None of the expected target columns were found in the dataset.\")\n",
    "\n",
    "# IMPORTANT: include ALL possible targets for safe dropping\n",
    "ALL_TARGET_COLS = [c for c in [COL_ABOVE, COL_BELOW, COL_DEPTH] if c]\n",
    "\n",
    "# ----------------- Helper: build X, y -----------------\n",
    "def build_xy(df_in: pd.DataFrame, target_col: str):\n",
    "    drop_cols = [c for c in EXCLUDE_PRED_COLS if c in df_in.columns]\n",
    "    work = df_in.drop(columns=drop_cols, errors='ignore').copy()\n",
    "    work = work.dropna(subset=[target_col])\n",
    "\n",
    "    y = work[target_col].astype(float).copy()\n",
    "\n",
    "    # Drop the explicit target AND any other known target columns to prevent leakage\n",
    "    X = work.drop(columns=list(set(ALL_TARGET_COLS + [target_col])), errors='ignore')\n",
    "\n",
    "    # Guard against accidental leakage\n",
    "    assert target_col not in X.columns, f\"Target leakage: {target_col} present in predictors!\"\n",
    "\n",
    "    non_numeric = X.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "    if non_numeric:\n",
    "        X = X.drop(columns=non_numeric)\n",
    "\n",
    "    # Sanity: no empty feature set\n",
    "    if X.shape[1] == 0:\n",
    "        raise ValueError(f\"No numeric predictors left after preprocessing for target '{target_col}'.\")\n",
    "    return X, y\n",
    "\n",
    "# ----------------- RandomizedSearch + LOOCV with per-fold R² -----------------\n",
    "def run_target_randomsearch_loocv(target_col: str, units_label: str = \"units\"):\n",
    "    X, y = build_xy(df, target_col)\n",
    "    if X.shape[1] == 0 or len(y) < 3:\n",
    "        print(f\"[ERROR] Not enough predictors or samples for '{target_col}'.\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\nTarget: {target_col} | X: {X.shape} | y: {y.shape}\")\n",
    "    y = y.reset_index(drop=True)\n",
    "    X = X.reset_index(drop=True)\n",
    "    out_prefix = target_col.replace('.', '_')\n",
    "\n",
    "    # 1. RandomizedSearchCV (global)\n",
    "    print(f\"\\n[{target_col}] Starting global RandomizedSearchCV with {N_ITER_SEARCH} iterations...\")\n",
    "    kfold = KFold(n_splits=min(INNER_FOLDS, len(y)), shuffle=True, random_state=RANDOM_STATE)\n",
    "    base = RandomForestRegressor(random_state=RANDOM_STATE, n_jobs=N_JOBS)\n",
    "    tuner = RandomizedSearchCV(\n",
    "        estimator=base,\n",
    "        param_distributions=RF_PARAM_DIST,\n",
    "        n_iter=N_ITER_SEARCH,\n",
    "        scoring=SCORER,\n",
    "        cv=kfold,\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=N_JOBS,\n",
    "        verbose=1,\n",
    "        refit=True,\n",
    "    )\n",
    "    tuner.fit(X, y)\n",
    "\n",
    "    # Leakage sanity check: the tuned model must NOT expect the target as a feature\n",
    "    tuned_features = list(getattr(tuner.best_estimator_, \"feature_names_in_\", []))\n",
    "    if target_col in tuned_features:\n",
    "        raise RuntimeError(\n",
    "            f\"Leakage detected: tuned model expects target '{target_col}' as a feature. \"\n",
    "            f\"Check preprocessing.\"\n",
    "        )\n",
    "\n",
    "    best_params = tuner.best_params_\n",
    "    best_neg_mse = float(tuner.best_score_)\n",
    "    best_rmse = float(np.sqrt(-best_neg_mse))\n",
    "    print(f\"[{target_col}] Best params: {best_params}\")\n",
    "    print(f\"[{target_col}] RandomizedSearch best CV RMSE: {best_rmse:.4f} {units_label}\")\n",
    "    rs_results = pd.DataFrame(tuner.cv_results_)\n",
    "    rs_results.to_csv(os.path.join(OUT_DIR, f\"{out_prefix}_random_search_results.csv\"), index=False)\n",
    "\n",
    "    # 2. LOOCV using best params\n",
    "    print(f\"\\n[{target_col}] Starting LOOCV with fixed best hyperparameters...\")\n",
    "    loo = LeaveOneOut()\n",
    "    n = len(y)\n",
    "    y_pred = np.zeros(n, dtype=float)\n",
    "    r2_folds = np.full(n, np.nan, dtype=float)  # one R² per left-out observation\n",
    "    train_means = np.full(n, np.nan, dtype=float)\n",
    "\n",
    "    for i, (train_idx, test_idx) in enumerate(loo.split(X), start=1):\n",
    "        Xtr, Xte = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        ytr = y.iloc[train_idx]\n",
    "        yte = y.iloc[test_idx].values[0]\n",
    "\n",
    "        model = RandomForestRegressor(random_state=RANDOM_STATE, n_jobs=N_JOBS, **best_params)\n",
    "        model.fit(Xtr, ytr)\n",
    "        yhat = model.predict(Xte)[0]\n",
    "\n",
    "        # store prediction\n",
    "        test_i = test_idx[0]\n",
    "        y_pred[test_i] = yhat\n",
    "\n",
    "        # per-fold R² for this left-out sample\n",
    "        mu_train = float(ytr.mean())\n",
    "        train_means[test_i] = mu_train\n",
    "        denom = (yte - mu_train)**2\n",
    "        num = (yte - yhat)**2\n",
    "\n",
    "        # if denom == 0, R² is undefined -> keep NaN\n",
    "        if denom != 0.0:\n",
    "            r2_val = 1.0 - (num / denom)\n",
    "            # clamp negative R² to 0\n",
    "            if r2_val < 0.0:\n",
    "                r2_val = 0.0\n",
    "            r2_folds[test_i] = r2_val\n",
    "\n",
    "        if i % 25 == 0 or i == n:\n",
    "            print(f\"  LOOCV progress: {i}/{n}\")\n",
    "\n",
    "    # Global LOOCV metrics over all predictions\n",
    "    rmse_global = mean_squared_error(y, y_pred, squared=False)\n",
    "    r2_raw_global = r2_score(y, y_pred)\n",
    "    # clamp negative global R² to 0 as well\n",
    "    r2_global = max(0.0, r2_raw_global)\n",
    "    print(f\"[{target_col}] LOOCV RMSE (global): {rmse_global:.4f} | R² (global, clamped): {r2_global:.4f} (raw: {r2_raw_global:.4f})\")\n",
    "\n",
    "    # Save per-sample predictions + per-fold R²\n",
    "    preds_df = pd.DataFrame({\n",
    "        \"index\": np.arange(n),\n",
    "        \"y_obs\": y.values,\n",
    "        \"y_pred\": y_pred,\n",
    "        \"train_mean_y\": train_means,\n",
    "        \"r2_loocv_fold\": r2_folds\n",
    "    })\n",
    "\n",
    "    # CSV for violin plot\n",
    "    violin_csv_path = os.path.join(OUT_DIR, f\"{out_prefix}_violin.csv\")\n",
    "    preds_df.to_csv(violin_csv_path, index=False)\n",
    "    print(f\"[{target_col}] Saved per-fold R² CSV: {violin_csv_path}\")\n",
    "\n",
    "    # Also keep the LOOCV predictions CSV\n",
    "    preds_path = os.path.join(OUT_DIR, f\"{out_prefix}_loocv_predictions.csv\")\n",
    "    preds_df.to_csv(preds_path, index=False)\n",
    "    print(f\"[{target_col}] Saved LOOCV predictions (with fold R²) to: {preds_path}\")\n",
    "\n",
    "    # Save summary metrics\n",
    "    pd.DataFrame({\n",
    "        \"target\": [target_col],\n",
    "        \"n\": [n],\n",
    "        \"n_predictors\": [X.shape[1]],\n",
    "        \"loocv_rmse_global\": [rmse_global],\n",
    "        \"loocv_r2_global_clamped\": [r2_global],\n",
    "        \"loocv_r2_global_raw\": [r2_raw_global],\n",
    "        \"random_search_best_rmse\": [best_rmse]\n",
    "    }).to_csv(os.path.join(OUT_DIR, f\"{out_prefix}_loocv_metrics.csv\"), index=False)\n",
    "\n",
    "    # Plot 1:1 scatter (global)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.scatterplot(x=preds_df[\"y_obs\"], y=preds_df[\"y_pred\"], s=18, edgecolor=None)\n",
    "    lo = float(np.nanmin([preds_df[\"y_obs\"].min(), preds_df[\"y_pred\"].min()]))\n",
    "    hi = float(np.nanmax([preds_df[\"y_obs\"].max(), preds_df[\"y_pred\"].max()]))\n",
    "    plt.plot([lo, hi], [lo, hi], 'k--', lw=2)\n",
    "    plt.xlabel(f\"Observed {target_col}\")\n",
    "    plt.ylabel(f\"Predicted {target_col}\")\n",
    "    plt.title(f\"{target_col}: LOOCV Obs vs Pred\\nRMSE={rmse_global:.3f}, R²={r2_global:.3f} (clamped)\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUT_DIR, f\"{out_prefix}_loocv_obs_pred.png\"), dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "    # ----------------- VIOLIN PLOT OF PER-FOLD R² -----------------\n",
    "    valid_r2 = preds_df[\"r2_loocv_fold\"].dropna()\n",
    "    if len(valid_r2) > 0:\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        sns.violinplot(y=valid_r2, cut=0)\n",
    "        plt.ylabel(\"Per-fold LOOCV R²\")\n",
    "        plt.title(f\"Distribution of LOOCV R² per left-out sample\\nTarget: {target_col}\")\n",
    "        plt.grid(axis='y', alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        violin_png_path = os.path.join(OUT_DIR, f\"{out_prefix}_violin.png\")\n",
    "        plt.savefig(violin_png_path, dpi=150)\n",
    "        plt.close()\n",
    "        print(f\"[{target_col}] Saved violin plot of per-fold R²: {violin_png_path}\")\n",
    "    else:\n",
    "        print(f\"[{target_col}] No valid per-fold R² values (all denominators zero). Skipping violin plot.\")\n",
    "\n",
    "    # Save model + metadata (with feature names!)\n",
    "    final_model = RandomForestRegressor(random_state=RANDOM_STATE, n_jobs=N_JOBS, **best_params)\n",
    "    final_model.fit(X, y)\n",
    "    model_path = os.path.join(MODEL_DIR, f\"rf_final_{out_prefix}.joblib\")\n",
    "    joblib.dump(final_model, model_path)\n",
    "\n",
    "    feature_names = list(getattr(final_model, \"feature_names_in_\", X.columns))\n",
    "\n",
    "    # --------------- FEATURE IMPORTANCE CSV + PLOT ---------------\n",
    "    importances = final_model.feature_importances_\n",
    "    fi_df = pd.DataFrame({\n",
    "        \"feature\": feature_names,\n",
    "        \"importance\": importances\n",
    "    }).sort_values(\"importance\", ascending=False)\n",
    "\n",
    "    fi_csv_path = os.path.join(OUT_DIR, f\"{out_prefix}_feature_importance.csv\")\n",
    "    fi_df.to_csv(fi_csv_path, index=False)\n",
    "    print(f\"[{target_col}] Saved feature importance CSV: {fi_csv_path}\")\n",
    "\n",
    "    top_n = min(30, len(fi_df))\n",
    "    fi_top = fi_df.head(top_n)\n",
    "\n",
    "    plt.figure(figsize=(10, max(6, 0.3 * top_n)))\n",
    "    sns.barplot(data=fi_top, x=\"importance\", y=\"feature\", orient=\"h\")\n",
    "    plt.xlabel(\"Random Forest feature importance\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "    plt.title(f\"Feature importance (top {top_n})\\nTarget: {target_col}\")\n",
    "    plt.tight_layout()\n",
    "    fi_png_path = os.path.join(OUT_DIR, f\"{out_prefix}_feature_importance.png\")\n",
    "    plt.savefig(fi_png_path, dpi=150)\n",
    "    plt.close()\n",
    "    print(f\"[{target_col}] Saved feature importance plot: {fi_png_path}\")\n",
    "    # ------------- END FEATURE IMPORTANCE BLOCK -------------\n",
    "\n",
    "    meta = {\n",
    "        \"target\": target_col,\n",
    "        \"loocv_rmse_global\": rmse_global,\n",
    "        \"loocv_r2_global_clamped\": r2_global,\n",
    "        \"loocv_r2_global_raw\": r2_raw_global,\n",
    "        \"best_params\": best_params,\n",
    "        \"model_path\": model_path,\n",
    "        \"n_samples\": n,\n",
    "        \"feature_names\": feature_names\n",
    "    }\n",
    "    with open(os.path.join(OUT_DIR, f\"{out_prefix}_final_model_metadata.json\"), \"w\") as f:\n",
    "        json.dump(meta, f, indent=2)\n",
    "\n",
    "    # Extra sanity message\n",
    "    print(f\"[{target_col}] Final model trained with {len(meta['feature_names'])} features; \"\n",
    "          f\"'{target_col}' in features? {target_col in meta['feature_names']}\")\n",
    "\n",
    "# ----------------- RUN FOR EACH TARGET -----------------\n",
    "for tcol, units in targets:\n",
    "    run_target_randomsearch_loocv(tcol, units)\n",
    "\n",
    "print(\"\\nDone.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0913cf05-45cd-4937-a522-df7c47611a3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a3cde46-7d10-453e-a00f-6cbc55cbac1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'t'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cd25c1-969b-4327-bf6e-4f55b09a3da0",
   "metadata": {},
   "source": [
    "Xgboost with tuning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-xgboost_gpu]",
   "language": "python",
   "name": "conda-env-.conda-xgboost_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
